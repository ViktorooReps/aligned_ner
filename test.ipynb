{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:09:15.221199Z",
     "start_time": "2024-12-07T11:09:10.106883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import BatchEncoding, PreTrainedTokenizer, AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers.data import data_collator\n",
    "\n",
    "from modelling_xlm_roberta import XLMRobertaForTokenClassification\n",
    "import nervaluate\n",
    "\n",
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "from typing import Iterable\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "device = 'cuda'\n",
    "model_dtype = torch.bfloat16\n",
    "torch.cuda.get_device_name(0)"
   ],
   "id": "164bfe6522ca666c",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     21\u001B[0m model_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbfloat16\n\u001B[0;32m---> 22\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_device_name\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/prompt_ner/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:493\u001B[0m, in \u001B[0;36mget_device_name\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_name\u001B[39m(device: Optional[_device_t] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    482\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Get the name of a device.\u001B[39;00m\n\u001B[1;32m    483\u001B[0m \n\u001B[1;32m    484\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    491\u001B[0m \u001B[38;5;124;03m        str: the name of the device\u001B[39;00m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_device_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[0;32m~/PycharmProjects/prompt_ner/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:523\u001B[0m, in \u001B[0;36mget_device_properties\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_properties\u001B[39m(device: _device_t) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _CudaDeviceProperties:\n\u001B[1;32m    514\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Get the properties of a device.\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \n\u001B[1;32m    516\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    521\u001B[0m \u001B[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 523\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[1;32m    524\u001B[0m     device \u001B[38;5;241m=\u001B[39m _get_device_index(device, optional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count():\n",
      "File \u001B[0;32m~/PycharmProjects/prompt_ner/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    308\u001B[0m     )\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    314\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Test that layer cutting works",
   "id": "bd4e31a4b6b090d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:09:17.624728Z",
     "start_time": "2024-12-07T11:09:16.557712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_test = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base')\n",
    "model_test"
   ],
   "id": "50cd8944790c35f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(901629, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:25:34.462156Z",
     "start_time": "2024-12-06T19:25:33.986864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_test = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base', skip_last_layer=True)\n",
    "model_test"
   ],
   "id": "45dbf4a4718b4f0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(901629, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-10): 11 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Works! Passing `skip_last_layer=True` removes the last layer in the transformer stack (11 x XLMRobertaLayer instead of 12 x XLMRobertaLayer)",
   "id": "d91e348b9d48ece2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Train models on the downstream tagging task and evaluate the knowledge transfer to a different language\n",
    "For this we will use CoNLL 2003 corpus (`eriktks/conll2003`, 14k examples) to train the model and Afrikaans NER Corpus (`nwu-ctext/afrikaans_ner_corpus`, 9k examples) to test the model. The validation is done over CoNLL 2003, only the final scores for Afrikaans are reported."
   ],
   "id": "9af1cd678fa696d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.077613Z",
     "start_time": "2024-12-06T19:25:52.307681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = load_dataset('eriktks/conll2003', split='train')\n",
    "valid_dataset = load_dataset('eriktks/conll2003', split='validation')\n",
    "test_dataset = load_dataset('nwu-ctext/afrikaans_ner_corpus', split='train')"
   ],
   "id": "19ee1cb470c3ca97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c5a44f9cbdb4889a89e7eb308a85d1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4736511aa72f42b08d8ba4a04bcd5468"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdedf3b38df447b692226e9790d16d5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62bddc30e9874a37b9f8f1853e20db4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2dc63aba5c445479460540c28d695db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7de8dc6a4acd4677a365a454f564dfa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.82k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4edd1e76c09740f795fd81a72e19166a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/945k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e475653da4524796a1931c3eaf605e64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e080aef0b884e5395e7bf108857f052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make sure that the labelling scheme is identical across datasets",
   "id": "ecafcb621612d84f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.081223Z",
     "start_time": "2024-12-06T19:26:20.078555Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset.features['ner_tags']",
   "id": "668a8c6cfaac7811",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.084101Z",
     "start_time": "2024-12-06T19:26:20.081694Z"
    }
   },
   "cell_type": "code",
   "source": "valid_dataset.features['ner_tags']",
   "id": "432d9997a6a8bcf1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.086733Z",
     "start_time": "2024-12-06T19:26:20.084795Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset.features['ner_tags']",
   "id": "8c160d6214600da3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['OUT', 'B-PERS', 'I-PERS', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The names are a bit different, but otherwise the schemes are identical",
   "id": "d61fbac113d2c666"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Convert word-level tags to subtoken-level tags",
   "id": "2e089cee56f48462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:30:00.398308Z",
     "start_time": "2024-12-06T19:29:56.297177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xlm_tok = AutoTokenizer.from_pretrained('facebook/xlm-v-base')\n",
    "xlm_tok_name = 'xlm-v'\n",
    "\n",
    "xlm_tok('test <mask> test', return_offsets_mapping=True)"
   ],
   "id": "7c3f74ba028a74e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1340, 901628, 1340, 2], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 4), (4, 11), (11, 16), (0, 0)]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:21:23.110803Z",
     "start_time": "2024-12-06T20:21:23.107609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for reference\n",
    "ner_tags_scheme = np.array(['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
    "ner_tags_ext    =          [  0,       2,       2,       4,       4,       6,       6,        8,        8]\n",
    "# the ext is used when we need to split one word into multiple sub tokens"
   ],
   "id": "cfb59f07b44af84f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:29.957380Z",
     "start_time": "2024-12-06T19:26:24.077956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(example: dict, tokenizer: PreTrainedTokenizer, tokenizer_name: str, max_length: int = 512) -> dict:\n",
    "    ner_tags: list[int] = example['ner_tags']\n",
    "    example_words: list[str] = example['tokens']\n",
    "    text = ' '.join(example_words)\n",
    "    \n",
    "    # map words to positions in text\n",
    "    word_positions: list[int] = example.get('word_positions', [])\n",
    "    \n",
    "    if len(word_positions) != len(example_words):\n",
    "        text_iterator = 0\n",
    "        for word in example_words:\n",
    "            while text[text_iterator:text_iterator + len(word)] != word:\n",
    "                text_iterator += 1\n",
    "                assert text_iterator < len(text)\n",
    "            \n",
    "            word_positions.append(text_iterator)\n",
    "    \n",
    "    encoding: BatchEncoding = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=max_length)\n",
    "    num_sub_tokens = len(encoding.offset_mapping)\n",
    "    \n",
    "    sub_token_iterator = 0\n",
    "    sub_token_ner_tags: list[int] = []\n",
    "    for word_id, ner_tag in enumerate(ner_tags):\n",
    "        word_start = word_positions[word_id]\n",
    "        word_end = word_start + len(example_words[word_id])\n",
    "        \n",
    "        # there may be some empty space between words. the sub tokens that include this empty space receive O label\n",
    "        # we compare with the end ([1]) to ensure that 0-length tokens are labelled as O (for example <CLS>)\n",
    "        while sub_token_iterator < num_sub_tokens and  encoding.offset_mapping[sub_token_iterator][1] <= word_start:\n",
    "            if encoding.offset_mapping[sub_token_iterator][1] - encoding.offset_mapping[sub_token_iterator][0] == 0:\n",
    "                # set to -100 for special tokens like <CLS>\n",
    "                sub_token_ner_tags.append(-100)\n",
    "            else:\n",
    "                sub_token_ner_tags.append(0)  # 0 = O\n",
    "            sub_token_iterator += 1\n",
    "            \n",
    "        ext_tag = ner_tags_ext[ner_tag]\n",
    "        \n",
    "        if sub_token_iterator < num_sub_tokens:\n",
    "            # the first sub token of a word receives original label, the rest receive extended label\n",
    "            sub_token_ner_tags.append(ner_tag)\n",
    "            sub_token_iterator += 1\n",
    "        \n",
    "        # again, we need to be careful about 0-length tokens, so we compare start ([0]) with the word end\n",
    "        while sub_token_iterator < num_sub_tokens and encoding.offset_mapping[sub_token_iterator][0] < word_end:\n",
    "            \n",
    "            # there is a weird quirk with transformers tokenizers: <SEP> token has (0, 0) offset \n",
    "            #   regardless of its real position, see https://github.com/huggingface/transformers/issues/35125\n",
    "            if encoding.offset_mapping[sub_token_iterator][1] - encoding.offset_mapping[sub_token_iterator][0] == 0:\n",
    "                sub_token_ner_tags.append(-100)\n",
    "            else:\n",
    "                sub_token_ner_tags.append(ext_tag)\n",
    "                \n",
    "            sub_token_iterator += 1\n",
    "    \n",
    "    # any tokens at the end (like <SEP>) receive O tokens\n",
    "    while sub_token_iterator < num_sub_tokens:\n",
    "        sub_token_iterator += 1\n",
    "        sub_token_ner_tags.append(0)\n",
    "        \n",
    "    return {\n",
    "        'word_positions': word_positions,\n",
    "        f'{tokenizer_name}_sub_tokens': encoding.input_ids,\n",
    "        f'{tokenizer_name}_sub_token_offsets': encoding.offset_mapping,\n",
    "        f'{tokenizer_name}_sub_token_ner_tags': sub_token_ner_tags,\n",
    "        'length': len(encoding.offset_mapping)\n",
    "    }\n",
    "\n",
    "tokenize_fn = partial(tokenize, tokenizer=xlm_tok, tokenizer_name=xlm_tok_name, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn)\n",
    "valid_dataset = valid_dataset.map(tokenize_fn)\n",
    "test_dataset = test_dataset.map(tokenize_fn)"
   ],
   "id": "21f16632e08f1c6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4840dc171de646ba9f546303a66f89b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd96d6a899b848d7ad6ff057fd606e30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "383aed25e5774537ad536fa5b6cc06f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:29.997429Z",
     "start_time": "2024-12-06T19:26:29.958462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for test_idx in range(25):\n",
    "    ner_tags = torch.as_tensor(train_dataset[test_idx]['xlm-v_sub_token_ner_tags'])\n",
    "    tokens = torch.as_tensor(train_dataset[test_idx]['xlm-v_sub_tokens'])\n",
    "    print('Text:', ' '.join(train_dataset[test_idx]['tokens']))\n",
    "    print('Ents:', xlm_tok.decode(tokens[ner_tags > 0]))\n",
    "    print()"
   ],
   "id": "d1bc289c17bf712c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: EU rejects German call to boycott British lamb .\n",
      "Ents: EU German British\n",
      "\n",
      "Text: Peter Blackburn\n",
      "Ents: Peter Blackburn\n",
      "\n",
      "Text: BRUSSELS 1996-08-22\n",
      "Ents: BRUSSELS\n",
      "\n",
      "Text: The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
      "Ents: European Commission German British\n",
      "\n",
      "Text: Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .\n",
      "Ents: Germany European Union Werner Zwingmann Britain\n",
      "\n",
      "Text: \" We do n't support any such recommendation because we do n't see any grounds for it , \" the Commission 's chief spokesman Nikolaus van der Pas told a news briefing .\n",
      "Ents: Commission Nikolaus van der Pas\n",
      "\n",
      "Text: He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .\n",
      "Ents: European Union\n",
      "\n",
      "Text: He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .\n",
      "Ents: EU Franz Fischler\n",
      "\n",
      "Text: Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease .\n",
      "Ents: Fischler EU-wide Britain France Bovine Spongiform Encephalopathy BSE\n",
      "\n",
      "Text: But Fischler agreed to review his proposal after the EU 's standing veterinary committee , mational animal health officials , questioned if such action was justified as there was only a slight risk to human health .\n",
      "Ents: Fischler EU\n",
      "\n",
      "Text: Spanish Farm Minister Loyola de Palacio had earlier accused Fischler at an EU farm ministers ' meeting of causing unjustified alarm through \" dangerous generalisation . \"\n",
      "Ents: Spanish Loyola de Palacio Fischler EU\n",
      "\n",
      "Text: .\n",
      "Ents: \n",
      "\n",
      "Text: Only France and Britain backed Fischler 's proposal .\n",
      "Ents: France Britain Fischler\n",
      "\n",
      "Text: The EU 's scientific veterinary and multidisciplinary committees are due to re-examine the issue early next month and make recommendations to the senior veterinary officials .\n",
      "Ents: EU\n",
      "\n",
      "Text: Sheep have long been known to contract scrapie , a brain-wasting disease similar to BSE which is believed to have been transferred to cattle through feed containing animal waste .\n",
      "Ents: BSE\n",
      "\n",
      "Text: British farmers denied on Thursday there was any danger to human health from their sheep , but expressed concern that German government advice to consumers to avoid British lamb might influence consumers across Europe .\n",
      "Ents: British German British Europe\n",
      "\n",
      "Text: \" What we have to be extremely careful of is how other countries are going to take Germany 's lead , \" Welsh National Farmers ' Union ( NFU ) chairman John Lloyd Jones said on BBC radio .\n",
      "Ents: Germany Welsh National Farmers'Union NFU John Lloyd Jones BBC radio\n",
      "\n",
      "Text: Bonn has led efforts to protect public health after consumer confidence collapsed in March after a British report suggested humans could contract an illness similar to mad cow disease by eating contaminated beef .\n",
      "Ents: Bonn British\n",
      "\n",
      "Text: Germany imported 47,600 sheep from Britain last year , nearly half of total imports .\n",
      "Ents: Germany Britain\n",
      "\n",
      "Text: It brought in 4,275 tonnes of British mutton , some 10 percent of overall imports .\n",
      "Ents: British\n",
      "\n",
      "Text: Rare Hendrix song draft sells for almost $ 17,000 .\n",
      "Ents: Hendrix\n",
      "\n",
      "Text: LONDON 1996-08-22\n",
      "Ents: LONDON\n",
      "\n",
      "Text: A rare early handwritten draft of a song by U.S. guitar legend Jimi Hendrix was sold for almost $ 17,000 on Thursday at an auction of some of the late musician 's favourite possessions .\n",
      "Ents: U.S. Jimi Hendrix\n",
      "\n",
      "Text: A Florida restaurant paid 10,925 pounds ( $ 16,935 ) for the draft of \" Ai n't no telling \" , which Hendrix penned on a piece of London hotel stationery in late 1966 .\n",
      "Ents: Florida Ain't no telling Hendrix London\n",
      "\n",
      "Text: At the end of a January 1967 concert in the English city of Nottingham he threw the sheet of paper into the audience , where it was retrieved by a fan .\n",
      "Ents: English Nottingham\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looks nice!",
   "id": "9234e8f0ab28fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:28:44.626907Z",
     "start_time": "2024-12-06T19:28:44.374015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset.save_to_disk('data/train')\n",
    "valid_dataset.save_to_disk('data/valid')\n",
    "test_dataset.save_to_disk('data/test')"
   ],
   "id": "8d7920ea056c2596",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "485329834fd7465aa6ec2087457d8894"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98d7310b332843b4a4ec9795c7ef1fdf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79b05ad9ab604913a8874bdecc8ba918"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:21:28.654403Z",
     "start_time": "2024-12-06T20:21:28.649874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, examples: Iterable[dict], tokenizer_name: str):\n",
    "        self.input_ids = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for example in examples:\n",
    "            self.input_ids.append(torch.as_tensor(example[f'{tokenizer_name}_sub_tokens']))\n",
    "            self.labels.append(torch.as_tensor(example[f'{tokenizer_name}_sub_token_ner_tags']))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "def collate_fn(inputs: list[(Tensor, Tensor)], *, pad_token: int) -> dict:\n",
    "    all_input_ids = []\n",
    "    all_labels = []\n",
    "    for input_ids, labels in inputs:\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    input_ids = pad_sequence(all_input_ids, batch_first=True, padding_value=pad_token)\n",
    "    \n",
    "    batch_size, seq_length = input_ids.shape\n",
    "\n",
    "    # do not attend to pad and pad does not attend to anything\n",
    "    pad_mask = (input_ids != pad_token)\n",
    "    attention_mask = (pad_mask.reshape(batch_size, 1, -1) != pad_mask.reshape(batch_size, -1, 1))\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': pad_sequence(all_labels, batch_first=True, padding_value=-100),\n",
    "        'attention_mask': attention_mask\n",
    "    }"
   ],
   "id": "2bbb670d6122a3f5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:22:19.960424Z",
     "start_time": "2024-12-06T20:22:19.954954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_ner_metrics(eval_pred) -> dict:\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    padding = (labels < 0)\n",
    "    \n",
    "    predictions = predictions[~padding]\n",
    "    labels = labels[~padding]\n",
    "\n",
    "    predictions = ner_tags_scheme[predictions]\n",
    "    labels = ner_tags_scheme[labels]\n",
    "\n",
    "    evaluator = nervaluate.Evaluator([labels], [predictions], tags=['PER', 'LOC', 'ORG', 'MISC'], loader='list')\n",
    "    results, results_per_tag, _, _ = evaluator.evaluate()\n",
    "\n",
    "    overall_metrics = results[\"strict\"]\n",
    "    \n",
    "    metrics = {\n",
    "        'overall_precision': overall_metrics['precision'],\n",
    "        'overall_recall': overall_metrics['recall'],\n",
    "        'overall_f1': overall_metrics['f1'],\n",
    "    }\n",
    "    \n",
    "    for tag, tag_metrics in results_per_tag.items():\n",
    "        metrics[f'{tag}_precision'] = tag_metrics['strict']['precision']\n",
    "        metrics[f'{tag}_recall'] = tag_metrics['strict']['recall']\n",
    "        metrics[f'{tag}_f1'] = tag_metrics['strict']['f1']\n",
    "\n",
    "    # Return desired metrics\n",
    "    return metrics"
   ],
   "id": "3da5ff8b55ce26e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Train a conventional model",
   "id": "c9559c9f274e9c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:22:20.602470Z",
     "start_time": "2024-12-06T20:22:20.599636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_run = 0\n",
    "model_name = 'facebook/xlm-v-base'"
   ],
   "id": "4a4988357b4e9d66",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:20:45.694972Z",
     "start_time": "2024-12-07T00:12:53.739133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_name = f'xlm-v-base-finetuned-l12-conll03/{datetime.now().strftime(\"%m-%d\")}/{n_run}'\n",
    "wandb.init(\n",
    "    project='ner-alignment',\n",
    "    name=run_name,\n",
    "    dir=run_name,\n",
    "    resume=False\n",
    ")\n",
    "n_run += 1\n",
    "\n",
    "model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    'facebook/xlm-v-base', \n",
    "    num_labels=9, \n",
    "    classifier_dropout=0.1, \n",
    "    hidden_dropout_prob=0.1\n",
    ")\n",
    "model.roberta.embeddings.requires_grad_(False)  # freeze input embeddings to avoid parameter shift (training on english and inferencing on africaans -> different tokens are activated)\n",
    "print(f\"Percentage of frozen modules: {100 * sum(1 for module in model.modules() if not any(p.requires_grad for p in module.parameters())) / sum(1 for module in model.modules()):.2f}%\")\n",
    "print(f\"Percentage of frozen parameters: {100 * sum(p.numel() for p in model.parameters() if not p.requires_grad) / sum(p.numel() for p in model.parameters()):.2f}%\")\n",
    "\n",
    "\n",
    "xlm_tok = AutoTokenizer.from_pretrained('facebook/xlm-v-base')\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=run_name,\n",
    "        overwrite_output_dir=True,\n",
    "        eval_strategy='steps',\n",
    "        eval_delay=0.001,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=128,\n",
    "        learning_rate=2e-5,\n",
    "        max_grad_norm=10,\n",
    "        max_steps=5000,\n",
    "        lr_scheduler_type='cosine',\n",
    "        lr_scheduler_kwargs={ 'num_cycles': 0.5 },\n",
    "        warmup_ratio=0.05,\n",
    "        adam_epsilon=1e-8,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.999,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        eval_steps=200,\n",
    "        dataloader_num_workers=4,\n",
    "        torch_compile=False,\n",
    "        include_num_input_tokens_seen=True,\n",
    "        disable_tqdm=True,\n",
    "        report_to='wandb'\n",
    "    ),\n",
    "    data_collator=partial(collate_fn, pad_token=xlm_tok.pad_token_id),\n",
    "    train_dataset=Dataset(load_from_disk('data/train'), tokenizer_name='xlm-v'),\n",
    "    eval_dataset=Dataset(load_from_disk('data/valid'), tokenizer_name='xlm-v'),\n",
    "    compute_metrics=compute_ner_metrics\n",
    ")\n",
    "trainer.train()\n",
    "wandb.finish()"
   ],
   "id": "c13273fe9f7aff09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Path xlm-v-base-finetuned-l12-conll03/12-07/16/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:3vdxf8zb) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ae3bdf51a2b4271916035407b3568db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/LOC_f1</td><td>▁▁</td></tr><tr><td>eval/LOC_precision</td><td>▁▁</td></tr><tr><td>eval/LOC_recall</td><td>▁▁</td></tr><tr><td>eval/MISC_f1</td><td>▁▁</td></tr><tr><td>eval/MISC_precision</td><td>▁▁</td></tr><tr><td>eval/MISC_recall</td><td>▁▁</td></tr><tr><td>eval/ORG_f1</td><td>▁▁</td></tr><tr><td>eval/ORG_precision</td><td>▁▁</td></tr><tr><td>eval/ORG_recall</td><td>▁▁</td></tr><tr><td>eval/PER_f1</td><td>▁▁</td></tr><tr><td>eval/PER_precision</td><td>▁▁</td></tr><tr><td>eval/PER_recall</td><td>▁▁</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/overall_f1</td><td>▁▁</td></tr><tr><td>eval/overall_precision</td><td>▁▁</td></tr><tr><td>eval/overall_recall</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▃▃▅▆▆█</td></tr><tr><td>train/global_step</td><td>▁▃▃▅▆▆█</td></tr><tr><td>train/grad_norm</td><td>█▂▁▃▂</td></tr><tr><td>train/learning_rate</td><td>▁▆███</td></tr><tr><td>train/loss</td><td>█▂▁▁▁</td></tr><tr><td>train/num_input_tokens_seen</td><td>▁▃▃▅▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/LOC_f1</td><td>0</td></tr><tr><td>eval/LOC_precision</td><td>0</td></tr><tr><td>eval/LOC_recall</td><td>0.0</td></tr><tr><td>eval/MISC_f1</td><td>0</td></tr><tr><td>eval/MISC_precision</td><td>0</td></tr><tr><td>eval/MISC_recall</td><td>0.0</td></tr><tr><td>eval/ORG_f1</td><td>0</td></tr><tr><td>eval/ORG_precision</td><td>0</td></tr><tr><td>eval/ORG_recall</td><td>0.0</td></tr><tr><td>eval/PER_f1</td><td>0</td></tr><tr><td>eval/PER_precision</td><td>0.0</td></tr><tr><td>eval/PER_recall</td><td>0.0</td></tr><tr><td>eval/loss</td><td>0.93357</td></tr><tr><td>eval/overall_f1</td><td>0</td></tr><tr><td>eval/overall_precision</td><td>0.0</td></tr><tr><td>eval/overall_recall</td><td>0.0</td></tr><tr><td>eval/runtime</td><td>0.798</td></tr><tr><td>eval/samples_per_second</td><td>4072.434</td></tr><tr><td>eval/steps_per_second</td><td>32.579</td></tr><tr><td>train/epoch</td><td>0.56948</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>1.71052</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.8168</td></tr><tr><td>train/num_input_tokens_seen</td><td>390432</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-shape-13</strong> at: <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/3vdxf8zb' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/3vdxf8zb</a><br/> View project at: <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>xlm-v-base-finetuned-l12-conll03/12-07/15/wandb/run-20241207_001155-3vdxf8zb/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.19.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:3vdxf8zb). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path xlm-v-base-finetuned-l12-conll03/12-07/16/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20241207_001253-qroa392l</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/qroa392l' target=\"_blank\">leafy-deluge-14</a></strong> to <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/qroa392l' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/qroa392l</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8089, 'grad_norm': 20.174489974975586, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.11389521640091116, 'num_input_tokens_seen': 76672}\n",
      "{'loss': 1.1744, 'grad_norm': 2.2620325088500977, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 158272}\n",
      "{'eval_loss': 0.95058673620224, 'eval_overall_precision': 0.010752688172043012, 'eval_overall_recall': 0.00016809547823163558, 'eval_overall_f1': 0.00033101621979476995, 'eval_PER_precision': 0.0, 'eval_PER_recall': 0.0, 'eval_PER_f1': 0, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0.034482758620689655, 'eval_MISC_recall': 0.0010799136069114472, 'eval_MISC_f1': 0.0020942408376963353, 'eval_runtime': 0.9845, 'eval_samples_per_second': 3301.272, 'eval_steps_per_second': 26.41, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 158272}\n",
      "{'loss': 0.7959, 'grad_norm': 6.600234031677246, 'learning_rate': 1.999453257340926e-05, 'epoch': 0.3416856492027335, 'num_input_tokens_seen': 236576}\n",
      "{'loss': 0.6236, 'grad_norm': 4.055098056793213, 'learning_rate': 1.9950829025450116e-05, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 313200}\n",
      "{'eval_loss': 0.6202005743980408, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0, 'eval_PER_precision': 0, 'eval_PER_recall': 0.0, 'eval_PER_f1': 0, 'eval_LOC_precision': 0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 0.8218, 'eval_samples_per_second': 3954.753, 'eval_steps_per_second': 31.638, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 313200}\n",
      "{'loss': 0.5855, 'grad_norm': 2.8700525760650635, 'learning_rate': 1.9863613034027224e-05, 'epoch': 0.5694760820045558, 'num_input_tokens_seen': 390432}\n",
      "{'loss': 0.5421, 'grad_norm': 2.9006245136260986, 'learning_rate': 1.973326597248006e-05, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 468592}\n",
      "{'eval_loss': 0.5926780104637146, 'eval_overall_precision': 0.2736757624398074, 'eval_overall_recall': 0.11464111615397546, 'eval_overall_f1': 0.16159222840895632, 'eval_PER_precision': 0.5440806045340051, 'eval_PER_recall': 0.3517915309446254, 'eval_PER_f1': 0.42729970326409494, 'eval_LOC_precision': 0.02295552367288379, 'eval_LOC_recall': 0.008709853021230268, 'eval_LOC_f1': 0.012628255722178378, 'eval_ORG_precision': 0.03879310344827586, 'eval_ORG_recall': 0.013392857142857142, 'eval_ORG_f1': 0.01991150442477876, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 3.7808, 'eval_samples_per_second': 859.599, 'eval_steps_per_second': 6.877, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 468592}\n",
      "{'loss': 0.5162, 'grad_norm': 3.316847085952759, 'learning_rate': 1.9560357815343577e-05, 'epoch': 0.7972665148063781, 'num_input_tokens_seen': 549056}\n",
      "{'loss': 0.457, 'grad_norm': 4.900198936462402, 'learning_rate': 1.934564464599461e-05, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 626848}\n",
      "{'eval_loss': 0.5336235165596008, 'eval_overall_precision': 0.15486528612781117, 'eval_overall_recall': 0.23382081022020507, 'eval_overall_f1': 0.18632375594400913, 'eval_PER_precision': 0.1275992438563327, 'eval_PER_recall': 0.2931596091205212, 'eval_PER_f1': 0.17780704642739548, 'eval_LOC_precision': 0.37790697674418605, 'eval_LOC_recall': 0.42460533478497553, 'eval_LOC_f1': 0.3998974621891823, 'eval_ORG_precision': 0.038565996740901685, 'eval_ORG_recall': 0.05282738095238095, 'eval_ORG_f1': 0.044583987441130304, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 13.0296, 'eval_samples_per_second': 249.432, 'eval_steps_per_second': 1.995, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 626848}\n",
      "{'loss': 0.4071, 'grad_norm': 2.755539655685425, 'learning_rate': 1.909006535049163e-05, 'epoch': 1.0250569476082005, 'num_input_tokens_seen': 705647}\n",
      "{'loss': 0.363, 'grad_norm': 7.606741905212402, 'learning_rate': 1.879473751206489e-05, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 784495}\n",
      "{'eval_loss': 0.3810890316963196, 'eval_overall_precision': 0.31152609448429386, 'eval_overall_recall': 0.42343250966549, 'eval_overall_f1': 0.3589597434983969, 'eval_PER_precision': 0.3361803894772805, 'eval_PER_recall': 0.5342019543973942, 'eval_PER_f1': 0.4126651289578528, 'eval_LOC_precision': 0.5118525021949079, 'eval_LOC_recall': 0.6347305389221557, 'eval_LOC_f1': 0.5667071688942892, 'eval_ORG_precision': 0.1820424272323631, 'eval_ORG_recall': 0.27455357142857145, 'eval_ORG_f1': 0.21892613467813707, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 10.2112, 'eval_samples_per_second': 318.277, 'eval_steps_per_second': 2.546, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 784495}\n",
      "{'loss': 0.3059, 'grad_norm': 5.741299152374268, 'learning_rate': 1.8460952524209355e-05, 'epoch': 1.2528473804100229, 'num_input_tokens_seen': 861071}\n",
      "{'loss': 0.3, 'grad_norm': 9.390608787536621, 'learning_rate': 1.8090169943749477e-05, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 936543}\n",
      "{'eval_loss': 0.3481009602546692, 'eval_overall_precision': 0.32361885453623923, 'eval_overall_recall': 0.42931585140359724, 'eval_overall_f1': 0.36904847915613037, 'eval_PER_precision': 0.28542646071188715, 'eval_PER_recall': 0.46145494028230183, 'eval_PER_f1': 0.35269709543568467, 'eval_LOC_precision': 0.5605180884323359, 'eval_LOC_recall': 0.6831790963527491, 'eval_LOC_f1': 0.6157998037291462, 'eval_ORG_precision': 0.24245748765770708, 'eval_ORG_recall': 0.3288690476190476, 'eval_ORG_f1': 0.27912851278812756, 'eval_MISC_precision': 0.008215962441314555, 'eval_MISC_recall': 0.00755939524838013, 'eval_MISC_f1': 0.007874015748031498, 'eval_runtime': 9.8713, 'eval_samples_per_second': 329.236, 'eval_steps_per_second': 2.634, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 936543}\n",
      "{'loss': 0.2703, 'grad_norm': 3.0660560131073, 'learning_rate': 1.7684011108568593e-05, 'epoch': 1.4806378132118452, 'num_input_tokens_seen': 1015087}\n",
      "{'loss': 0.262, 'grad_norm': 2.712602376937866, 'learning_rate': 1.7244252047910893e-05, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1092351}\n",
      "{'eval_loss': 0.3424839973449707, 'eval_overall_precision': 0.34, 'eval_overall_recall': 0.44293158514035974, 'eval_overall_f1': 0.38469961311044604, 'eval_PER_precision': 0.3073984022229941, 'eval_PER_recall': 0.4804560260586319, 'eval_PER_f1': 0.37492056767633974, 'eval_LOC_precision': 0.5678342377898372, 'eval_LOC_recall': 0.6265650517147523, 'eval_LOC_f1': 0.5957556935817806, 'eval_ORG_precision': 0.24733475479744135, 'eval_ORG_recall': 0.34523809523809523, 'eval_ORG_f1': 0.28819875776397513, 'eval_MISC_precision': 0.13946280991735538, 'eval_MISC_recall': 0.14578833693304535, 'eval_MISC_f1': 0.14255543822597674, 'eval_runtime': 9.4925, 'eval_samples_per_second': 342.376, 'eval_steps_per_second': 2.739, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1092351}\n",
      "{'loss': 0.2544, 'grad_norm': 5.017814636230469, 'learning_rate': 1.6772815716257414e-05, 'epoch': 1.7084282460136673, 'num_input_tokens_seen': 1172831}\n",
      "{'loss': 0.2417, 'grad_norm': 3.4244954586029053, 'learning_rate': 1.6271763584735373e-05, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1251359}\n",
      "{'eval_loss': 0.3130649924278259, 'eval_overall_precision': 0.42703648175912046, 'eval_overall_recall': 0.5745503445957304, 'eval_overall_f1': 0.48993048090016483, 'eval_PER_precision': 0.37989711119905023, 'eval_PER_recall': 0.5211726384364821, 'eval_PER_f1': 0.43945983062485694, 'eval_LOC_precision': 0.6076190476190476, 'eval_LOC_recall': 0.6946107784431138, 'eval_LOC_f1': 0.6482092964185928, 'eval_ORG_precision': 0.3524936601859679, 'eval_ORG_recall': 0.6205357142857143, 'eval_ORG_f1': 0.4495956873315364, 'eval_MISC_precision': 0.34421364985163205, 'eval_MISC_recall': 0.3758099352051836, 'eval_MISC_f1': 0.35931853381517814, 'eval_runtime': 8.4761, 'eval_samples_per_second': 383.431, 'eval_steps_per_second': 3.067, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1251359}\n",
      "{'loss': 0.2196, 'grad_norm': 4.901675224304199, 'learning_rate': 1.5743286626829437e-05, 'epoch': 1.9362186788154898, 'num_input_tokens_seen': 1325695}\n",
      "{'loss': 0.1998, 'grad_norm': 5.715210437774658, 'learning_rate': 1.5189695737812153e-05, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1404999}\n",
      "{'eval_loss': 0.30999428033828735, 'eval_overall_precision': 0.3942995615047311, 'eval_overall_recall': 0.5743822491174987, 'eval_overall_f1': 0.46760177899418404, 'eval_PER_precision': 0.32064, 'eval_PER_recall': 0.5439739413680782, 'eval_PER_f1': 0.4034628548419569, 'eval_LOC_precision': 0.6020362992474546, 'eval_LOC_recall': 0.7403375068045727, 'eval_LOC_f1': 0.6640625000000001, 'eval_ORG_precision': 0.2930337078651685, 'eval_ORG_recall': 0.4851190476190476, 'eval_ORG_f1': 0.36536845054637146, 'eval_MISC_precision': 0.3812677388836329, 'eval_MISC_recall': 0.4352051835853132, 'eval_MISC_f1': 0.4064548663640948, 'eval_runtime': 9.8373, 'eval_samples_per_second': 330.375, 'eval_steps_per_second': 2.643, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1404999}\n",
      "{'loss': 0.1915, 'grad_norm': 4.182936668395996, 'learning_rate': 1.461341162978688e-05, 'epoch': 2.164009111617312, 'num_input_tokens_seen': 1482071}\n",
      "{'loss': 0.1919, 'grad_norm': 3.928917407989502, 'learning_rate': 1.4016954246529697e-05, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1561335}\n",
      "{'eval_loss': 0.2960781157016754, 'eval_overall_precision': 0.4361928616155291, 'eval_overall_recall': 0.5854765506807866, 'eval_overall_f1': 0.4999282330988948, 'eval_PER_precision': 0.3815406976744186, 'eval_PER_recall': 0.5700325732899023, 'eval_PER_f1': 0.457117979973879, 'eval_LOC_precision': 0.6123076923076923, 'eval_LOC_recall': 0.7583015786608601, 'eval_LOC_f1': 0.6775291828793775, 'eval_ORG_precision': 0.3389473684210526, 'eval_ORG_recall': 0.4791666666666667, 'eval_ORG_f1': 0.3970406905055487, 'eval_MISC_precision': 0.3742911153119093, 'eval_MISC_recall': 0.42764578833693306, 'eval_MISC_f1': 0.39919354838709675, 'eval_runtime': 8.6308, 'eval_samples_per_second': 376.559, 'eval_steps_per_second': 3.012, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1561335}\n",
      "{'loss': 0.1827, 'grad_norm': 3.9468612670898438, 'learning_rate': 1.3402931744416432e-05, 'epoch': 2.3917995444191344, 'num_input_tokens_seen': 1637959}\n",
      "{'loss': 0.1719, 'grad_norm': 3.826040029525757, 'learning_rate': 1.2774029087618448e-05, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1713687}\n",
      "{'eval_loss': 0.29489266872406006, 'eval_overall_precision': 0.44625203353772996, 'eval_overall_recall': 0.5994284753740124, 'eval_overall_f1': 0.5116212338593974, 'eval_PER_precision': 0.37857142857142856, 'eval_PER_recall': 0.5466883821932682, 'eval_PER_f1': 0.4473567303420702, 'eval_LOC_precision': 0.6053604436229205, 'eval_LOC_recall': 0.713119216113228, 'eval_LOC_f1': 0.6548362909272681, 'eval_ORG_precision': 0.36971998101566206, 'eval_ORG_recall': 0.5796130952380952, 'eval_ORG_f1': 0.4514633439582729, 'eval_MISC_precision': 0.44339622641509435, 'eval_MISC_recall': 0.5075593952483801, 'eval_MISC_f1': 0.47331319234642494, 'eval_runtime': 8.4685, 'eval_samples_per_second': 383.774, 'eval_steps_per_second': 3.07, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1713687}\n",
      "{'loss': 0.1606, 'grad_norm': 5.590986728668213, 'learning_rate': 1.213299630743747e-05, 'epoch': 2.619589977220957, 'num_input_tokens_seen': 1791719}\n",
      "{'loss': 0.1618, 'grad_norm': 3.448587417602539, 'learning_rate': 1.148263647711842e-05, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 1868679}\n",
      "{'eval_loss': 0.27693089842796326, 'eval_overall_precision': 0.4780678851174935, 'eval_overall_recall': 0.6155656412842494, 'eval_overall_f1': 0.5381732676904989, 'eval_PER_precision': 0.4277227722772277, 'eval_PER_recall': 0.5863192182410424, 'eval_PER_f1': 0.49461873139455004, 'eval_LOC_precision': 0.6166666666666667, 'eval_LOC_recall': 0.7653783342406096, 'eval_LOC_f1': 0.6830216176827788, 'eval_ORG_precision': 0.388268156424581, 'eval_ORG_recall': 0.5171130952380952, 'eval_ORG_f1': 0.4435226547543076, 'eval_MISC_precision': 0.4516431924882629, 'eval_MISC_recall': 0.519438444924406, 'eval_MISC_f1': 0.4831742842792567, 'eval_runtime': 7.9816, 'eval_samples_per_second': 407.184, 'eval_steps_per_second': 3.257, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 1868679}\n",
      "{'loss': 0.1693, 'grad_norm': 3.0098984241485596, 'learning_rate': 1.0825793454723325e-05, 'epoch': 2.847380410022779, 'num_input_tokens_seen': 1950135}\n",
      "{'loss': 0.1568, 'grad_norm': 7.15994119644165, 'learning_rate': 1.0165339447663586e-05, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2028199}\n",
      "{'eval_loss': 0.2975044846534729, 'eval_overall_precision': 0.45203415369161226, 'eval_overall_recall': 0.6051437216338881, 'eval_overall_f1': 0.5175016171925537, 'eval_PER_precision': 0.40119536794919686, 'eval_PER_recall': 0.5830618892508144, 'eval_PER_f1': 0.47532639964593937, 'eval_LOC_precision': 0.603998096144693, 'eval_LOC_recall': 0.6908002177463255, 'eval_LOC_f1': 0.6444895886236668, 'eval_ORG_precision': 0.3748133399701344, 'eval_ORG_recall': 0.5602678571428571, 'eval_ORG_f1': 0.44915001491201906, 'eval_MISC_precision': 0.4282073067119796, 'eval_MISC_recall': 0.5442764578833693, 'eval_MISC_f1': 0.4793152639087018, 'eval_runtime': 8.6887, 'eval_samples_per_second': 374.05, 'eval_steps_per_second': 2.992, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2028199}\n",
      "{'loss': 0.1571, 'grad_norm': 7.083609104156494, 'learning_rate': 9.504162453267776e-06, 'epoch': 3.075170842824601, 'num_input_tokens_seen': 2105449}\n",
      "{'loss': 0.1477, 'grad_norm': 4.827695369720459, 'learning_rate': 8.84515363030414e-06, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2181993}\n",
      "{'eval_loss': 0.3173108398914337, 'eval_overall_precision': 0.4627450980392157, 'eval_overall_recall': 0.6148932593713229, 'eval_overall_f1': 0.5280785332755883, 'eval_PER_precision': 0.47965571205007823, 'eval_PER_recall': 0.6655808903365906, 'eval_PER_f1': 0.5575261482492041, 'eval_LOC_precision': 0.5503035559410234, 'eval_LOC_recall': 0.6908002177463255, 'eval_LOC_f1': 0.6125995655322231, 'eval_ORG_precision': 0.3618352450469239, 'eval_ORG_recall': 0.5163690476190477, 'eval_ORG_f1': 0.42550582464745557, 'eval_MISC_precision': 0.41688888888888886, 'eval_MISC_recall': 0.5064794816414687, 'eval_MISC_f1': 0.4573378839590444, 'eval_runtime': 8.1847, 'eval_samples_per_second': 397.085, 'eval_steps_per_second': 3.177, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2181993}\n",
      "{'loss': 0.1434, 'grad_norm': 9.189094543457031, 'learning_rate': 8.191194656678905e-06, 'epoch': 3.3029612756264237, 'num_input_tokens_seen': 2258121}\n",
      "{'loss': 0.1377, 'grad_norm': 5.165278911590576, 'learning_rate': 7.545145128592009e-06, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2339049}\n",
      "{'eval_loss': 0.31797266006469727, 'eval_overall_precision': 0.44676258992805756, 'eval_overall_recall': 0.6263237518910741, 'eval_overall_f1': 0.5215200503884106, 'eval_PER_precision': 0.4266617155588563, 'eval_PER_recall': 0.6237785016286646, 'eval_PER_f1': 0.5067254685777288, 'eval_LOC_precision': 0.6025350837483024, 'eval_LOC_recall': 0.7245508982035929, 'eval_LOC_f1': 0.6579337617399903, 'eval_ORG_precision': 0.344675209898365, 'eval_ORG_recall': 0.5803571428571429, 'eval_ORG_f1': 0.43249237593568063, 'eval_MISC_precision': 0.39659574468085107, 'eval_MISC_recall': 0.5032397408207343, 'eval_MISC_f1': 0.44359828653022376, 'eval_runtime': 8.5523, 'eval_samples_per_second': 380.015, 'eval_steps_per_second': 3.04, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2339049}\n",
      "{'loss': 0.1315, 'grad_norm': 5.054487228393555, 'learning_rate': 6.909830056250527e-06, 'epoch': 3.5307517084282463, 'num_input_tokens_seen': 2419209}\n",
      "{'loss': 0.1314, 'grad_norm': 3.8630919456481934, 'learning_rate': 6.2880275108177915e-06, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2499209}\n",
      "{'eval_loss': 0.2860950529575348, 'eval_overall_precision': 0.46162570888468807, 'eval_overall_recall': 0.6157337367624811, 'eval_overall_f1': 0.5276577355229041, 'eval_PER_precision': 0.38955672426746807, 'eval_PER_recall': 0.5629750271444083, 'eval_PER_f1': 0.4604795737122558, 'eval_LOC_precision': 0.6011586452762924, 'eval_LOC_recall': 0.7343494828524768, 'eval_LOC_f1': 0.6611124724332271, 'eval_ORG_precision': 0.41040462427745666, 'eval_ORG_recall': 0.5811011904761905, 'eval_ORG_f1': 0.4810594394825994, 'eval_MISC_precision': 0.4404973357015986, 'eval_MISC_recall': 0.5356371490280778, 'eval_MISC_f1': 0.48343079922027293, 'eval_runtime': 8.281, 'eval_samples_per_second': 392.462, 'eval_steps_per_second': 3.14, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2499209}\n",
      "{'loss': 0.1382, 'grad_norm': 5.842213153839111, 'learning_rate': 5.6824564766150724e-06, 'epoch': 3.7585421412300684, 'num_input_tokens_seen': 2576569}\n",
      "{'loss': 0.1314, 'grad_norm': 5.323875904083252, 'learning_rate': 5.095764961694923e-06, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2653561}\n",
      "{'eval_loss': 0.3148070275783539, 'eval_overall_precision': 0.46777392166584036, 'eval_overall_recall': 0.6343923348461926, 'eval_overall_f1': 0.5384889776699722, 'eval_PER_precision': 0.4821150855365474, 'eval_PER_recall': 0.6731813246471227, 'eval_PER_f1': 0.5618486633439058, 'eval_LOC_precision': 0.5719861231569818, 'eval_LOC_recall': 0.7180185084376701, 'eval_LOC_f1': 0.6367366642529568, 'eval_ORG_precision': 0.35721247563352826, 'eval_ORG_recall': 0.5453869047619048, 'eval_ORG_f1': 0.43168433451118965, 'eval_MISC_precision': 0.4235500878734622, 'eval_MISC_recall': 0.5205183585313174, 'eval_MISC_f1': 0.4670542635658914, 'eval_runtime': 8.2591, 'eval_samples_per_second': 393.505, 'eval_steps_per_second': 3.148, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2653561}\n",
      "{'loss': 0.1287, 'grad_norm': 6.76910924911499, 'learning_rate': 4.530518418775734e-06, 'epoch': 3.9863325740318905, 'num_input_tokens_seen': 2732649}\n",
      "{'loss': 0.1221, 'grad_norm': 3.163895845413208, 'learning_rate': 3.989188527169749e-06, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 2810839}\n",
      "{'eval_loss': 0.2826387584209442, 'eval_overall_precision': 0.4823453608247423, 'eval_overall_recall': 0.6291813750210119, 'eval_overall_f1': 0.5460646290757897, 'eval_PER_precision': 0.43370699652106687, 'eval_PER_recall': 0.6091205211726385, 'eval_PER_f1': 0.5066606457439602, 'eval_LOC_precision': 0.6203925323121111, 'eval_LOC_recall': 0.7054980947196516, 'eval_LOC_f1': 0.6602139582272033, 'eval_ORG_precision': 0.4255874673629243, 'eval_ORG_recall': 0.6063988095238095, 'eval_ORG_f1': 0.5001534212948757, 'eval_MISC_precision': 0.43627031650983744, 'eval_MISC_recall': 0.550755939524838, 'eval_MISC_f1': 0.48687350835322196, 'eval_runtime': 8.0086, 'eval_samples_per_second': 405.812, 'eval_steps_per_second': 3.246, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 2810839}\n",
      "{'loss': 0.1248, 'grad_norm': 6.945343971252441, 'learning_rate': 3.4741423847583134e-06, 'epoch': 4.214123006833713, 'num_input_tokens_seen': 2888231}\n",
      "{'loss': 0.1181, 'grad_norm': 3.7955641746520996, 'learning_rate': 2.9876321572751143e-06, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 2968263}\n",
      "{'eval_loss': 0.30533695220947266, 'eval_overall_precision': 0.4603366840256752, 'eval_overall_recall': 0.6389309127584468, 'eval_overall_f1': 0.5351260030972829, 'eval_PER_precision': 0.44935262757044936, 'eval_PER_recall': 0.6406080347448425, 'eval_PER_f1': 0.5282005371530886, 'eval_LOC_precision': 0.5679487179487179, 'eval_LOC_recall': 0.723462166575939, 'eval_LOC_f1': 0.6363418721570505, 'eval_ORG_precision': 0.39052631578947367, 'eval_ORG_recall': 0.5520833333333334, 'eval_ORG_f1': 0.4574599260172626, 'eval_MISC_precision': 0.39539899352983465, 'eval_MISC_recall': 0.593952483801296, 'eval_MISC_f1': 0.4747518342684506, 'eval_runtime': 8.5978, 'eval_samples_per_second': 378.006, 'eval_steps_per_second': 3.024, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 2968263}\n",
      "{'loss': 0.1163, 'grad_norm': 2.246997833251953, 'learning_rate': 2.5317852301584642e-06, 'epoch': 4.4419134396355355, 'num_input_tokens_seen': 3044967}\n",
      "{'loss': 0.1167, 'grad_norm': 4.053560733795166, 'learning_rate': 2.1085949060360654e-06, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3122231}\n",
      "{'eval_loss': 0.29452797770500183, 'eval_overall_precision': 0.4620123203285421, 'eval_overall_recall': 0.642965204236006, 'eval_overall_f1': 0.5376721956705088, 'eval_PER_precision': 0.4518375241779497, 'eval_PER_recall': 0.6340933767643865, 'eval_PER_f1': 0.5276711091032302, 'eval_LOC_precision': 0.5834064969271291, 'eval_LOC_recall': 0.723462166575939, 'eval_LOC_f1': 0.6459295261239367, 'eval_ORG_precision': 0.3839243498817967, 'eval_ORG_recall': 0.6041666666666666, 'eval_ORG_f1': 0.46949985544955186, 'eval_MISC_precision': 0.39661798616448884, 'eval_MISC_recall': 0.5572354211663066, 'eval_MISC_f1': 0.4634036820835204, 'eval_runtime': 8.7281, 'eval_samples_per_second': 372.358, 'eval_steps_per_second': 2.979, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3122231}\n",
      "{'loss': 0.1169, 'grad_norm': 1.9090274572372437, 'learning_rate': 1.7199116885197996e-06, 'epoch': 4.669703872437358, 'num_input_tokens_seen': 3200151}\n",
      "{'loss': 0.1123, 'grad_norm': 5.569982528686523, 'learning_rate': 1.367435190424261e-06, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3278631}\n",
      "{'eval_loss': 0.2892790138721466, 'eval_overall_precision': 0.48014440433212996, 'eval_overall_recall': 0.6483442595394184, 'eval_overall_f1': 0.5517093405807467, 'eval_PER_precision': 0.4883537307540466, 'eval_PER_recall': 0.6715526601520087, 'eval_PER_f1': 0.5654857142857144, 'eval_LOC_precision': 0.5847766636280766, 'eval_LOC_recall': 0.698421339139902, 'eval_LOC_f1': 0.63656660878194, 'eval_ORG_precision': 0.39812992125984253, 'eval_ORG_recall': 0.6019345238095238, 'eval_ORG_f1': 0.479265402843602, 'eval_MISC_precision': 0.41444270015698587, 'eval_MISC_recall': 0.5701943844492441, 'eval_MISC_f1': 0.4799999999999999, 'eval_runtime': 8.1377, 'eval_samples_per_second': 399.378, 'eval_steps_per_second': 3.195, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3278631}\n",
      "{'loss': 0.1196, 'grad_norm': 3.5794129371643066, 'learning_rate': 1.0527067017923654e-06, 'epoch': 4.89749430523918, 'num_input_tokens_seen': 3357111}\n",
      "{'loss': 0.1116, 'grad_norm': 10.00965404510498, 'learning_rate': 7.771024502261526e-07, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3436536}\n",
      "{'eval_loss': 0.2902405858039856, 'eval_overall_precision': 0.47462243129487497, 'eval_overall_recall': 0.6444780635400907, 'eval_overall_f1': 0.5466600128323947, 'eval_PER_precision': 0.4670224933282501, 'eval_PER_recall': 0.6650380021715526, 'eval_PER_f1': 0.5487122060470325, 'eval_LOC_precision': 0.5878949710725412, 'eval_LOC_recall': 0.7191072400653239, 'eval_LOC_f1': 0.6469147894221351, 'eval_ORG_precision': 0.3863979848866499, 'eval_ORG_recall': 0.5706845238095238, 'eval_ORG_f1': 0.46079903875037553, 'eval_MISC_precision': 0.4260016353229763, 'eval_MISC_recall': 0.562634989200864, 'eval_MISC_f1': 0.48487668683108426, 'eval_runtime': 8.0881, 'eval_samples_per_second': 401.826, 'eval_steps_per_second': 3.215, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3436536}\n",
      "{'loss': 0.1144, 'grad_norm': 7.037797451019287, 'learning_rate': 5.418275829936537e-07, 'epoch': 5.125284738041002, 'num_input_tokens_seen': 3516360}\n",
      "{'loss': 0.0999, 'grad_norm': 1.8106447458267212, 'learning_rate': 3.4791089722651437e-07, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3592952}\n",
      "{'eval_loss': 0.2899230718612671, 'eval_overall_precision': 0.4795752654590881, 'eval_overall_recall': 0.645318540931249, 'eval_overall_f1': 0.5502364913286513, 'eval_PER_precision': 0.4704980842911877, 'eval_PER_recall': 0.6666666666666666, 'eval_PER_f1': 0.5516621743036837, 'eval_LOC_precision': 0.5846359982134882, 'eval_LOC_recall': 0.7125748502994012, 'eval_LOC_f1': 0.6422963689892051, 'eval_ORG_precision': 0.40408163265306124, 'eval_ORG_recall': 0.5892857142857143, 'eval_ORG_f1': 0.47941888619854717, 'eval_MISC_precision': 0.42642140468227424, 'eval_MISC_recall': 0.550755939524838, 'eval_MISC_f1': 0.4806786050895382, 'eval_runtime': 8.1, 'eval_samples_per_second': 401.237, 'eval_steps_per_second': 3.21, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3592952}\n",
      "{'loss': 0.1072, 'grad_norm': 4.770160675048828, 'learning_rate': 1.9620034125190645e-07, 'epoch': 5.353075170842825, 'num_input_tokens_seen': 3672664}\n",
      "{'loss': 0.1035, 'grad_norm': 2.524550199508667, 'learning_rate': 8.735930673024806e-08, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 3750152}\n",
      "{'eval_loss': 0.29003334045410156, 'eval_overall_precision': 0.4763730826323602, 'eval_overall_recall': 0.6473356866700286, 'eval_overall_f1': 0.5488491413097698, 'eval_PER_precision': 0.4685714285714286, 'eval_PER_recall': 0.6677524429967426, 'eval_PER_f1': 0.5507051712558765, 'eval_LOC_precision': 0.5887809187279152, 'eval_LOC_recall': 0.7256396298312466, 'eval_LOC_f1': 0.6500853450377957, 'eval_ORG_precision': 0.3941532258064516, 'eval_ORG_recall': 0.5818452380952381, 'eval_ORG_f1': 0.4699519230769231, 'eval_MISC_precision': 0.41783649876135426, 'eval_MISC_recall': 0.5464362850971922, 'eval_MISC_f1': 0.47356106691623767, 'eval_runtime': 8.1797, 'eval_samples_per_second': 397.326, 'eval_steps_per_second': 3.179, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 3750152}\n",
      "{'loss': 0.1174, 'grad_norm': 6.250620365142822, 'learning_rate': 2.1863727812254653e-08, 'epoch': 5.5808656036446465, 'num_input_tokens_seen': 3825400}\n",
      "{'loss': 0.1057, 'grad_norm': 2.461894989013672, 'learning_rate': 0.0, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n",
      "{'eval_loss': 0.29064786434173584, 'eval_overall_precision': 0.47854130488712476, 'eval_overall_recall': 0.64851235501765, 'eval_overall_f1': 0.5507101563057597, 'eval_PER_precision': 0.4717633499807914, 'eval_PER_recall': 0.6666666666666666, 'eval_PER_f1': 0.5525309336332958, 'eval_LOC_precision': 0.589585172109444, 'eval_LOC_recall': 0.7272727272727273, 'eval_LOC_f1': 0.6512308067267853, 'eval_ORG_precision': 0.39585439838220426, 'eval_ORG_recall': 0.5825892857142857, 'eval_ORG_f1': 0.47140276941601444, 'eval_MISC_precision': 0.4205761316872428, 'eval_MISC_recall': 0.5518358531317494, 'eval_MISC_f1': 0.4773470340962167, 'eval_runtime': 8.1929, 'eval_samples_per_second': 396.685, 'eval_steps_per_second': 3.173, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n",
      "{'train_runtime': 448.4382, 'train_samples_per_second': 178.397, 'train_steps_per_second': 11.15, 'train_loss': 0.2733513090133667, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.2733513090133667, metrics={'train_runtime': 448.4382, 'train_samples_per_second': 178.397, 'train_steps_per_second': 11.15, 'train_loss': 0.2733513090133667, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:22:31.733751Z",
     "start_time": "2024-12-07T00:20:45.696450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results_l12 = trainer.evaluate(Dataset(load_from_disk('data/test'), tokenizer_name='xlm-v'), metric_key_prefix='transfer')\n",
    "test_results_l12"
   ],
   "id": "d24056baa716f185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transfer_loss': 0.6437795758247375, 'transfer_overall_precision': 0.08365958539246518, 'transfer_overall_recall': 0.18153331940672654, 'transfer_overall_f1': 0.11453550952265888, 'transfer_PER_precision': 0.049324023176348236, 'transfer_PER_recall': 0.16093068347067377, 'transfer_PER_f1': 0.07550602683647942, 'transfer_LOC_precision': 0.1402452140245214, 'transfer_LOC_recall': 0.35726027397260274, 'transfer_LOC_f1': 0.2014210688909484, 'transfer_ORG_precision': 0.09822494627079519, 'transfer_ORG_recall': 0.34421199442119943, 'transfer_ORG_f1': 0.1528362645528858, 'transfer_MISC_precision': 0.053885579720182854, 'transfer_MISC_recall': 0.05647502903600465, 'transfer_MISC_f1': 0.05514992556886652, 'transfer_runtime': 104.7546, 'transfer_samples_per_second': 85.552, 'transfer_steps_per_second': 0.678, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transfer_loss': 0.6437795758247375,\n",
       " 'transfer_overall_precision': 0.08365958539246518,\n",
       " 'transfer_overall_recall': 0.18153331940672654,\n",
       " 'transfer_overall_f1': 0.11453550952265888,\n",
       " 'transfer_PER_precision': 0.049324023176348236,\n",
       " 'transfer_PER_recall': 0.16093068347067377,\n",
       " 'transfer_PER_f1': 0.07550602683647942,\n",
       " 'transfer_LOC_precision': 0.1402452140245214,\n",
       " 'transfer_LOC_recall': 0.35726027397260274,\n",
       " 'transfer_LOC_f1': 0.2014210688909484,\n",
       " 'transfer_ORG_precision': 0.09822494627079519,\n",
       " 'transfer_ORG_recall': 0.34421199442119943,\n",
       " 'transfer_ORG_f1': 0.1528362645528858,\n",
       " 'transfer_MISC_precision': 0.053885579720182854,\n",
       " 'transfer_MISC_recall': 0.05647502903600465,\n",
       " 'transfer_MISC_f1': 0.05514992556886652,\n",
       " 'transfer_runtime': 104.7546,\n",
       " 'transfer_samples_per_second': 85.552,\n",
       " 'transfer_steps_per_second': 0.678,\n",
       " 'epoch': 5.694760820045558,\n",
       " 'num_input_tokens_seen': 3906776}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:30:09.291734Z",
     "start_time": "2024-12-07T00:22:31.734987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_name = f'xlm-v-base-finetuned-l11-conll03/{datetime.now().strftime(\"%m-%d\")}/{n_run}'\n",
    "wandb.init(resume=False, reinit=True, dir=run_name, project='ner-alignment')\n",
    "n_run += 1\n",
    "model = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base', num_labels=9, classifier_dropout=0.1, hidden_dropout_prob=0.1, skip_last_layer=True)\n",
    "model.roberta.embeddings.requires_grad_(False)  # freeze input embeddings to avoid parameter shift (training on english and inferencing on africaans -> different tokens are activated)\n",
    "xlm_tok = AutoTokenizer.from_pretrained('facebook/xlm-v-base')\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=run_name,\n",
    "        overwrite_output_dir=True,\n",
    "        eval_strategy='steps',\n",
    "        eval_delay=0.001,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=128,\n",
    "        learning_rate=2e-5,\n",
    "        max_grad_norm=10,\n",
    "        max_steps=5000,\n",
    "        lr_scheduler_type='cosine',\n",
    "        lr_scheduler_kwargs={ 'num_cycles': 0.5 },\n",
    "        warmup_ratio=0.05,\n",
    "        adam_epsilon=1e-8,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.999,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        bf16=True,\n",
    "        eval_steps=200,\n",
    "        dataloader_num_workers=4,\n",
    "        torch_compile=True,\n",
    "        include_num_input_tokens_seen=True,\n",
    "        disable_tqdm=True\n",
    "    ),\n",
    "    data_collator=partial(collate_fn, pad_token=xlm_tok.pad_token_id),\n",
    "    train_dataset=Dataset(load_from_disk('data/train'), tokenizer_name='xlm-v'),\n",
    "    eval_dataset=Dataset(load_from_disk('data/valid'), tokenizer_name='xlm-v'),\n",
    "    compute_metrics=compute_ner_metrics\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "90cb1610c1f20c9a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Path xlm-v-base-finetuned-l11-conll03/12-07/17/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:qroa392l) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1c01886088947288e80df6856c99fb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "W&B sync reduced upload amount by 3.3%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/LOC_f1</td><td>▁▁▁▅▇▇▇██████▇███████████</td></tr><tr><td>eval/LOC_precision</td><td>▁▁▁▅▇▇▇██████▇██▇█▇██████</td></tr><tr><td>eval/LOC_recall</td><td>▁▁▁▅▇▇▇▇████▇▇███▇██▇████</td></tr><tr><td>eval/MISC_f1</td><td>▁▁▁▁▁▁▃▆▇▇████▇██████████</td></tr><tr><td>eval/MISC_precision</td><td>▂▁▁▁▁▁▃▆▇▇███▇▇███▇▇▇██▇█</td></tr><tr><td>eval/MISC_recall</td><td>▁▁▁▁▁▁▃▅▆▆▇▇▇▇▇▇▇▇████▇▇█</td></tr><tr><td>eval/ORG_f1</td><td>▁▁▁▂▄▅▅▇▆▇▇▇▇▇▇█▇█▇██▇███</td></tr><tr><td>eval/ORG_precision</td><td>▁▁▂▂▄▅▅▇▆▇▇▇▇▇▇█▇█▇▇█▇█▇█</td></tr><tr><td>eval/ORG_recall</td><td>▁▁▁▂▄▅▅█▆▆█▇▇▇██▇█▇██▇███</td></tr><tr><td>eval/PER_f1</td><td>▁▁▆▃▆▅▆▆▆▇▇▇▇█▇▇█▇███████</td></tr><tr><td>eval/PER_precision</td><td>▁▁█▃▅▅▅▆▅▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇</td></tr><tr><td>eval/PER_recall</td><td>▁▁▅▄▇▆▆▆▇▇▇▇▇█▇▇█▇███████</td></tr><tr><td>eval/loss</td><td>█▅▄▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/overall_f1</td><td>▁▁▃▃▆▆▆▇▇▇▇██████████████</td></tr><tr><td>eval/overall_precision</td><td>▁▁▅▃▆▆▆▇▇▇▇███▇██████████</td></tr><tr><td>eval/overall_recall</td><td>▁▁▂▄▆▆▆▇▇▇▇██████████████</td></tr><tr><td>eval/runtime</td><td>▁▁▃█▆▆▆▅▆▅▅▅▆▅▅▅▅▅▅▆▅▅▅▅▅</td></tr><tr><td>eval/samples_per_second</td><td>▇█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▇█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▁▃▂▁▂▂▁▂▄▁▁▂▂▂▂▂▂▂▂▃▃▂▄▂▂▃▂▂▃▂▁▁▂▂▄▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▄▇██████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/num_input_tokens_seen</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/transfer_LOC_f1</td><td>▁</td></tr><tr><td>train/transfer_LOC_precision</td><td>▁</td></tr><tr><td>train/transfer_LOC_recall</td><td>▁</td></tr><tr><td>train/transfer_MISC_f1</td><td>▁</td></tr><tr><td>train/transfer_MISC_precision</td><td>▁</td></tr><tr><td>train/transfer_MISC_recall</td><td>▁</td></tr><tr><td>train/transfer_ORG_f1</td><td>▁</td></tr><tr><td>train/transfer_ORG_precision</td><td>▁</td></tr><tr><td>train/transfer_ORG_recall</td><td>▁</td></tr><tr><td>train/transfer_PER_f1</td><td>▁</td></tr><tr><td>train/transfer_PER_precision</td><td>▁</td></tr><tr><td>train/transfer_PER_recall</td><td>▁</td></tr><tr><td>train/transfer_loss</td><td>▁</td></tr><tr><td>train/transfer_overall_f1</td><td>▁</td></tr><tr><td>train/transfer_overall_precision</td><td>▁</td></tr><tr><td>train/transfer_overall_recall</td><td>▁</td></tr><tr><td>train/transfer_runtime</td><td>▁</td></tr><tr><td>train/transfer_samples_per_second</td><td>▁</td></tr><tr><td>train/transfer_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/LOC_f1</td><td>0.65123</td></tr><tr><td>eval/LOC_precision</td><td>0.58959</td></tr><tr><td>eval/LOC_recall</td><td>0.72727</td></tr><tr><td>eval/MISC_f1</td><td>0.47735</td></tr><tr><td>eval/MISC_precision</td><td>0.42058</td></tr><tr><td>eval/MISC_recall</td><td>0.55184</td></tr><tr><td>eval/ORG_f1</td><td>0.4714</td></tr><tr><td>eval/ORG_precision</td><td>0.39585</td></tr><tr><td>eval/ORG_recall</td><td>0.58259</td></tr><tr><td>eval/PER_f1</td><td>0.55253</td></tr><tr><td>eval/PER_precision</td><td>0.47176</td></tr><tr><td>eval/PER_recall</td><td>0.66667</td></tr><tr><td>eval/loss</td><td>0.29065</td></tr><tr><td>eval/overall_f1</td><td>0.55071</td></tr><tr><td>eval/overall_precision</td><td>0.47854</td></tr><tr><td>eval/overall_recall</td><td>0.64851</td></tr><tr><td>eval/runtime</td><td>8.1929</td></tr><tr><td>eval/samples_per_second</td><td>396.685</td></tr><tr><td>eval/steps_per_second</td><td>3.173</td></tr><tr><td>total_flos</td><td>1993930669516176.0</td></tr><tr><td>train/epoch</td><td>5.69476</td></tr><tr><td>train/global_step</td><td>5000</td></tr><tr><td>train/grad_norm</td><td>2.46189</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1057</td></tr><tr><td>train/num_input_tokens_seen</td><td>3906776</td></tr><tr><td>train/transfer_LOC_f1</td><td>0.20142</td></tr><tr><td>train/transfer_LOC_precision</td><td>0.14025</td></tr><tr><td>train/transfer_LOC_recall</td><td>0.35726</td></tr><tr><td>train/transfer_MISC_f1</td><td>0.05515</td></tr><tr><td>train/transfer_MISC_precision</td><td>0.05389</td></tr><tr><td>train/transfer_MISC_recall</td><td>0.05648</td></tr><tr><td>train/transfer_ORG_f1</td><td>0.15284</td></tr><tr><td>train/transfer_ORG_precision</td><td>0.09822</td></tr><tr><td>train/transfer_ORG_recall</td><td>0.34421</td></tr><tr><td>train/transfer_PER_f1</td><td>0.07551</td></tr><tr><td>train/transfer_PER_precision</td><td>0.04932</td></tr><tr><td>train/transfer_PER_recall</td><td>0.16093</td></tr><tr><td>train/transfer_loss</td><td>0.64378</td></tr><tr><td>train/transfer_overall_f1</td><td>0.11454</td></tr><tr><td>train/transfer_overall_precision</td><td>0.08366</td></tr><tr><td>train/transfer_overall_recall</td><td>0.18153</td></tr><tr><td>train/transfer_runtime</td><td>104.7546</td></tr><tr><td>train/transfer_samples_per_second</td><td>85.552</td></tr><tr><td>train/transfer_steps_per_second</td><td>0.678</td></tr><tr><td>train_loss</td><td>0.27335</td></tr><tr><td>train_runtime</td><td>448.4382</td></tr><tr><td>train_samples_per_second</td><td>178.397</td></tr><tr><td>train_steps_per_second</td><td>11.15</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-deluge-14</strong> at: <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/qroa392l' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/qroa392l</a><br/> View project at: <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>xlm-v-base-finetuned-l12-conll03/12-07/16/wandb/run-20241207_001253-qroa392l/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.19.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:qroa392l). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path xlm-v-base-finetuned-l11-conll03/12-07/17/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20241207_002231-654mnd33</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/654mnd33' target=\"_blank\">dark-galaxy-15</a></strong> to <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/654mnd33' target=\"_blank\">https://wandb.ai/viktoroo-sch-epfl/ner-alignment/runs/654mnd33</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3132, 'grad_norm': 2.603902578353882, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.11389521640091116, 'num_input_tokens_seen': 76672}\n",
      "{'loss': 0.7704, 'grad_norm': 3.464730978012085, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 158272}\n",
      "{'eval_loss': 0.5994405746459961, 'eval_overall_precision': 0.27987543791358505, 'eval_overall_recall': 0.12086064884854597, 'eval_overall_f1': 0.168818971589575, 'eval_PER_precision': 0.40070921985815605, 'eval_PER_recall': 0.30673181324647125, 'eval_PER_f1': 0.34747847478474786, 'eval_LOC_precision': 0.19207317073170732, 'eval_LOC_recall': 0.06859009254218836, 'eval_LOC_f1': 0.10108303249097474, 'eval_ORG_precision': 0.06796116504854369, 'eval_ORG_recall': 0.020833333333333332, 'eval_ORG_f1': 0.03189066059225513, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 3.5957, 'eval_samples_per_second': 903.866, 'eval_steps_per_second': 7.231, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 158272}\n",
      "{'loss': 0.5017, 'grad_norm': 4.419711589813232, 'learning_rate': 1.999453257340926e-05, 'epoch': 0.3416856492027335, 'num_input_tokens_seen': 236576}\n",
      "{'loss': 0.3734, 'grad_norm': 6.042629241943359, 'learning_rate': 1.9950829025450116e-05, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 313200}\n",
      "{'eval_loss': 0.39433547854423523, 'eval_overall_precision': 0.3215936905085668, 'eval_overall_recall': 0.39754580601781814, 'eval_overall_f1': 0.3555588964895137, 'eval_PER_precision': 0.15348032857760485, 'eval_PER_recall': 0.19272529858849077, 'eval_PER_f1': 0.17087845968712398, 'eval_LOC_precision': 0.5709376534118802, 'eval_LOC_recall': 0.633097441480675, 'eval_LOC_f1': 0.6004130098089829, 'eval_ORG_precision': 0.20211742059672763, 'eval_ORG_recall': 0.3125, 'eval_ORG_f1': 0.24547048509643482, 'eval_MISC_precision': 0.4611231101511879, 'eval_MISC_recall': 0.4611231101511879, 'eval_MISC_f1': 0.4611231101511879, 'eval_runtime': 9.0252, 'eval_samples_per_second': 360.102, 'eval_steps_per_second': 2.881, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 313200}\n",
      "{'loss': 0.3391, 'grad_norm': 3.6867246627807617, 'learning_rate': 1.9863613034027224e-05, 'epoch': 0.5694760820045558, 'num_input_tokens_seen': 390432}\n",
      "{'loss': 0.3005, 'grad_norm': 6.019204616546631, 'learning_rate': 1.973326597248006e-05, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 468592}\n",
      "{'eval_loss': 0.28962692618370056, 'eval_overall_precision': 0.44105793450881614, 'eval_overall_recall': 0.5886703647671878, 'eval_overall_f1': 0.5042839657282742, 'eval_PER_precision': 0.3859466943579093, 'eval_PER_recall': 0.6053203040173725, 'eval_PER_f1': 0.4713591206932995, 'eval_LOC_precision': 0.6123876123876124, 'eval_LOC_recall': 0.6673924877517692, 'eval_LOC_f1': 0.638707996874186, 'eval_ORG_precision': 0.33991333654309097, 'eval_ORG_recall': 0.5252976190476191, 'eval_ORG_f1': 0.4127448114586378, 'eval_MISC_precision': 0.46810699588477367, 'eval_MISC_recall': 0.49136069114470843, 'eval_MISC_f1': 0.4794520547945206, 'eval_runtime': 8.2844, 'eval_samples_per_second': 392.303, 'eval_steps_per_second': 3.138, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 468592}\n",
      "{'loss': 0.2802, 'grad_norm': 4.310842037200928, 'learning_rate': 1.9560357815343577e-05, 'epoch': 0.7972665148063781, 'num_input_tokens_seen': 549056}\n",
      "{'loss': 0.2493, 'grad_norm': 3.660649299621582, 'learning_rate': 1.934564464599461e-05, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 626848}\n",
      "{'eval_loss': 0.33385249972343445, 'eval_overall_precision': 0.3949102183180468, 'eval_overall_recall': 0.51386787695411, 'eval_overall_f1': 0.4466033601168737, 'eval_PER_precision': 0.2948021722265322, 'eval_PER_recall': 0.41259500542888167, 'eval_PER_f1': 0.3438914027149321, 'eval_LOC_precision': 0.5284147557328016, 'eval_LOC_recall': 0.5770277626565051, 'eval_LOC_f1': 0.5516523549310435, 'eval_ORG_precision': 0.3787139689578714, 'eval_ORG_recall': 0.6354166666666666, 'eval_ORG_f1': 0.47457627118644063, 'eval_MISC_precision': 0.4246119733924612, 'eval_MISC_recall': 0.4136069114470842, 'eval_MISC_f1': 0.4190371991247265, 'eval_runtime': 8.5852, 'eval_samples_per_second': 378.557, 'eval_steps_per_second': 3.028, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 626848}\n",
      "{'loss': 0.2417, 'grad_norm': 2.5203795433044434, 'learning_rate': 1.909006535049163e-05, 'epoch': 1.0250569476082005, 'num_input_tokens_seen': 705647}\n",
      "{'loss': 0.2252, 'grad_norm': 5.289560794830322, 'learning_rate': 1.879473751206489e-05, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 784495}\n",
      "{'eval_loss': 0.29823994636535645, 'eval_overall_precision': 0.455663430420712, 'eval_overall_recall': 0.5916960833753572, 'eval_overall_f1': 0.5148456925552142, 'eval_PER_precision': 0.4448621553884712, 'eval_PER_recall': 0.5781758957654723, 'eval_PER_f1': 0.5028328611898017, 'eval_LOC_precision': 0.598875351452671, 'eval_LOC_recall': 0.6956995100707676, 'eval_LOC_f1': 0.6436665827247544, 'eval_ORG_precision': 0.3469601677148847, 'eval_ORG_recall': 0.49255952380952384, 'eval_ORG_f1': 0.40713407134071344, 'eval_MISC_precision': 0.3995345228859581, 'eval_MISC_recall': 0.5561555075593952, 'eval_MISC_f1': 0.4650112866817156, 'eval_runtime': 8.0567, 'eval_samples_per_second': 403.39, 'eval_steps_per_second': 3.227, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 784495}\n",
      "{'loss': 0.2009, 'grad_norm': 3.074557304382324, 'learning_rate': 1.8460952524209355e-05, 'epoch': 1.2528473804100229, 'num_input_tokens_seen': 861071}\n",
      "{'loss': 0.2063, 'grad_norm': 5.518322467803955, 'learning_rate': 1.8090169943749477e-05, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 936543}\n",
      "{'eval_loss': 0.28353390097618103, 'eval_overall_precision': 0.4267737296260786, 'eval_overall_recall': 0.5985879979828542, 'eval_overall_f1': 0.4982858742041558, 'eval_PER_precision': 0.3471229785633697, 'eval_PER_recall': 0.501085776330076, 'eval_PER_f1': 0.41013108198178183, 'eval_LOC_precision': 0.5810147299509002, 'eval_LOC_recall': 0.7729994556341862, 'eval_LOC_f1': 0.6633964027096474, 'eval_ORG_precision': 0.3553246753246753, 'eval_ORG_recall': 0.5089285714285714, 'eval_ORG_f1': 0.4184765983481187, 'eval_MISC_precision': 0.40577507598784196, 'eval_MISC_recall': 0.5766738660907127, 'eval_MISC_f1': 0.4763603925066904, 'eval_runtime': 9.2021, 'eval_samples_per_second': 353.18, 'eval_steps_per_second': 2.825, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 936543}\n",
      "{'loss': 0.1927, 'grad_norm': 5.355875492095947, 'learning_rate': 1.7684011108568593e-05, 'epoch': 1.4806378132118452, 'num_input_tokens_seen': 1015087}\n",
      "{'loss': 0.2008, 'grad_norm': 2.6354105472564697, 'learning_rate': 1.7244252047910893e-05, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1092351}\n",
      "{'eval_loss': 0.26713570952415466, 'eval_overall_precision': 0.4471002641841741, 'eval_overall_recall': 0.5974113296352328, 'eval_overall_f1': 0.5114404950352569, 'eval_PER_precision': 0.39839766933721776, 'eval_PER_recall': 0.5939196525515744, 'eval_PER_f1': 0.4768962510897995, 'eval_LOC_precision': 0.5683905268245529, 'eval_LOC_recall': 0.6401741970604246, 'eval_LOC_f1': 0.6021505376344086, 'eval_ORG_precision': 0.38164493480441325, 'eval_ORG_recall': 0.5662202380952381, 'eval_ORG_f1': 0.45596165368484126, 'eval_MISC_precision': 0.4587719298245614, 'eval_MISC_recall': 0.5647948164146869, 'eval_MISC_f1': 0.5062923523717328, 'eval_runtime': 8.3927, 'eval_samples_per_second': 387.241, 'eval_steps_per_second': 3.098, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1092351}\n",
      "{'loss': 0.1886, 'grad_norm': 3.9321413040161133, 'learning_rate': 1.6772815716257414e-05, 'epoch': 1.7084282460136673, 'num_input_tokens_seen': 1172831}\n",
      "{'loss': 0.1826, 'grad_norm': 4.512164115905762, 'learning_rate': 1.6271763584735373e-05, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1251359}\n",
      "{'eval_loss': 0.2738385796546936, 'eval_overall_precision': 0.4594890510948905, 'eval_overall_recall': 0.6348966212808875, 'eval_overall_f1': 0.5331357188227821, 'eval_PER_precision': 0.44252662504590523, 'eval_PER_recall': 0.6541802388707926, 'eval_PER_f1': 0.5279299014238773, 'eval_LOC_precision': 0.6137961335676626, 'eval_LOC_recall': 0.7604790419161677, 'eval_LOC_f1': 0.6793095064429856, 'eval_ORG_precision': 0.3416666666666667, 'eval_ORG_recall': 0.5491071428571429, 'eval_ORG_f1': 0.4212328767123288, 'eval_MISC_precision': 0.411875589066918, 'eval_MISC_recall': 0.4719222462203024, 'eval_MISC_f1': 0.439859084046301, 'eval_runtime': 8.2979, 'eval_samples_per_second': 391.664, 'eval_steps_per_second': 3.133, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1251359}\n",
      "{'loss': 0.1766, 'grad_norm': 5.9478631019592285, 'learning_rate': 1.5743286626829437e-05, 'epoch': 1.9362186788154898, 'num_input_tokens_seen': 1325695}\n",
      "{'loss': 0.1581, 'grad_norm': 4.0998430252075195, 'learning_rate': 1.5189695737812153e-05, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1404999}\n",
      "{'eval_loss': 0.2709701657295227, 'eval_overall_precision': 0.4502668607472101, 'eval_overall_recall': 0.6239704151958312, 'eval_overall_f1': 0.5230747551609948, 'eval_PER_precision': 0.3870166725789287, 'eval_PER_recall': 0.5922909880564604, 'eval_PER_f1': 0.46813988414503327, 'eval_LOC_precision': 0.602866779089376, 'eval_LOC_recall': 0.7784431137724551, 'eval_LOC_f1': 0.679496317415063, 'eval_ORG_precision': 0.3869014859658778, 'eval_ORG_recall': 0.5230654761904762, 'eval_ORG_f1': 0.44479595064852895, 'eval_MISC_precision': 0.3948220064724919, 'eval_MISC_recall': 0.5269978401727862, 'eval_MISC_f1': 0.4514338575393154, 'eval_runtime': 8.4801, 'eval_samples_per_second': 383.252, 'eval_steps_per_second': 3.066, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1404999}\n",
      "{'loss': 0.1462, 'grad_norm': 4.889649868011475, 'learning_rate': 1.461341162978688e-05, 'epoch': 2.164009111617312, 'num_input_tokens_seen': 1482071}\n",
      "{'loss': 0.1556, 'grad_norm': 1.9928432703018188, 'learning_rate': 1.4016954246529697e-05, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1561335}\n",
      "{'eval_loss': 0.25937387347221375, 'eval_overall_precision': 0.4793959559764525, 'eval_overall_recall': 0.6296856614557068, 'eval_overall_f1': 0.5443580614691564, 'eval_PER_precision': 0.4381977671451356, 'eval_PER_recall': 0.5966340933767644, 'eval_PER_f1': 0.5052873563218391, 'eval_LOC_precision': 0.6229287953425885, 'eval_LOC_recall': 0.7572128470332063, 'eval_LOC_f1': 0.6835380835380835, 'eval_ORG_precision': 0.40211935303959845, 'eval_ORG_recall': 0.5364583333333334, 'eval_ORG_f1': 0.45967484858144725, 'eval_MISC_precision': 0.41796875, 'eval_MISC_recall': 0.5777537796976242, 'eval_MISC_f1': 0.485040797824116, 'eval_runtime': 7.8986, 'eval_samples_per_second': 411.466, 'eval_steps_per_second': 3.292, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1561335}\n",
      "{'loss': 0.1469, 'grad_norm': 2.468360424041748, 'learning_rate': 1.3402931744416432e-05, 'epoch': 2.3917995444191344, 'num_input_tokens_seen': 1637959}\n",
      "{'loss': 0.1406, 'grad_norm': 5.197323799133301, 'learning_rate': 1.2774029087618448e-05, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1713687}\n",
      "{'eval_loss': 0.2709812521934509, 'eval_overall_precision': 0.45176828495373306, 'eval_overall_recall': 0.5990922844175491, 'eval_overall_f1': 0.5151033386327504, 'eval_PER_precision': 0.35901271503365745, 'eval_PER_recall': 0.5211726384364821, 'eval_PER_f1': 0.4251550044286979, 'eval_LOC_precision': 0.6012950971322849, 'eval_LOC_recall': 0.7076755579749592, 'eval_LOC_f1': 0.6501625406351588, 'eval_ORG_precision': 0.41630669546436283, 'eval_ORG_recall': 0.5736607142857143, 'eval_ORG_f1': 0.48247809762202754, 'eval_MISC_precision': 0.443796835970025, 'eval_MISC_recall': 0.5755939524838013, 'eval_MISC_f1': 0.5011753643629525, 'eval_runtime': 8.4749, 'eval_samples_per_second': 383.487, 'eval_steps_per_second': 3.068, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1713687}\n",
      "{'loss': 0.1293, 'grad_norm': 6.489768981933594, 'learning_rate': 1.213299630743747e-05, 'epoch': 2.619589977220957, 'num_input_tokens_seen': 1791719}\n",
      "{'loss': 0.1345, 'grad_norm': 6.398703098297119, 'learning_rate': 1.148263647711842e-05, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 1868679}\n",
      "{'eval_loss': 0.2530602514743805, 'eval_overall_precision': 0.4962041884816754, 'eval_overall_recall': 0.6372499579761305, 'eval_overall_f1': 0.5579512841268675, 'eval_PER_precision': 0.4391554702495202, 'eval_PER_recall': 0.6210640608034745, 'eval_PER_f1': 0.514504160107938, 'eval_LOC_precision': 0.6373526745240253, 'eval_LOC_recall': 0.7653783342406096, 'eval_LOC_f1': 0.6955231263912935, 'eval_ORG_precision': 0.42671394799054374, 'eval_ORG_recall': 0.5372023809523809, 'eval_ORG_f1': 0.47562582345191046, 'eval_MISC_precision': 0.45646437994722955, 'eval_MISC_recall': 0.5604751619870411, 'eval_MISC_f1': 0.5031507513330101, 'eval_runtime': 7.5174, 'eval_samples_per_second': 432.328, 'eval_steps_per_second': 3.459, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 1868679}\n",
      "{'loss': 0.1415, 'grad_norm': 1.9365668296813965, 'learning_rate': 1.0825793454723325e-05, 'epoch': 2.847380410022779, 'num_input_tokens_seen': 1950135}\n",
      "{'loss': 0.1333, 'grad_norm': 5.286771774291992, 'learning_rate': 1.0165339447663586e-05, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2028199}\n",
      "{'eval_loss': 0.26834437251091003, 'eval_overall_precision': 0.48318804483188044, 'eval_overall_recall': 0.652210455538746, 'eval_overall_f1': 0.5551183918735246, 'eval_PER_precision': 0.4561611374407583, 'eval_PER_recall': 0.6270358306188925, 'eval_PER_f1': 0.5281207133058985, 'eval_LOC_precision': 0.608058608058608, 'eval_LOC_recall': 0.7229178007621121, 'eval_LOC_f1': 0.6605322059189256, 'eval_ORG_precision': 0.40436893203883495, 'eval_ORG_recall': 0.6197916666666666, 'eval_ORG_f1': 0.4894242068155112, 'eval_MISC_precision': 0.44976076555023925, 'eval_MISC_recall': 0.6090712742980562, 'eval_MISC_f1': 0.5174311926605504, 'eval_runtime': 7.9445, 'eval_samples_per_second': 409.087, 'eval_steps_per_second': 3.273, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2028199}\n",
      "{'loss': 0.1278, 'grad_norm': 10.111981391906738, 'learning_rate': 9.504162453267776e-06, 'epoch': 3.075170842824601, 'num_input_tokens_seen': 2105449}\n",
      "{'loss': 0.12, 'grad_norm': 4.643320560455322, 'learning_rate': 8.84515363030414e-06, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2181993}\n",
      "{'eval_loss': 0.25765755772590637, 'eval_overall_precision': 0.5057067603160668, 'eval_overall_recall': 0.6777609682299546, 'eval_overall_f1': 0.579227122539865, 'eval_PER_precision': 0.5010012014417301, 'eval_PER_recall': 0.6791530944625407, 'eval_PER_f1': 0.5766305600368749, 'eval_LOC_precision': 0.6236979166666666, 'eval_LOC_recall': 0.7822536744692433, 'eval_LOC_f1': 0.694035257184255, 'eval_ORG_precision': 0.4229122055674518, 'eval_ORG_recall': 0.5877976190476191, 'eval_ORG_f1': 0.49190535491905363, 'eval_MISC_precision': 0.42484662576687116, 'eval_MISC_recall': 0.5982721382289417, 'eval_MISC_f1': 0.49686098654708516, 'eval_runtime': 7.8159, 'eval_samples_per_second': 415.817, 'eval_steps_per_second': 3.327, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2181993}\n",
      "{'loss': 0.1204, 'grad_norm': 6.430139064788818, 'learning_rate': 8.191194656678905e-06, 'epoch': 3.3029612756264237, 'num_input_tokens_seen': 2258121}\n",
      "{'loss': 0.1137, 'grad_norm': 2.6817641258239746, 'learning_rate': 7.545145128592009e-06, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2339049}\n",
      "{'eval_loss': 0.2737866938114166, 'eval_overall_precision': 0.4732946836067596, 'eval_overall_recall': 0.6449823499747857, 'eval_overall_f1': 0.5459590210586226, 'eval_PER_precision': 0.4288483908491663, 'eval_PER_recall': 0.6004343105320304, 'eval_PER_f1': 0.5003392897534494, 'eval_LOC_precision': 0.6069142125480154, 'eval_LOC_recall': 0.7740881872618399, 'eval_LOC_f1': 0.6803827751196172, 'eval_ORG_precision': 0.41710388247639035, 'eval_ORG_recall': 0.5915178571428571, 'eval_ORG_f1': 0.48923076923076925, 'eval_MISC_precision': 0.40187646598905397, 'eval_MISC_recall': 0.5550755939524838, 'eval_MISC_f1': 0.4662131519274377, 'eval_runtime': 8.2008, 'eval_samples_per_second': 396.301, 'eval_steps_per_second': 3.17, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2339049}\n",
      "{'loss': 0.1091, 'grad_norm': 3.271926164627075, 'learning_rate': 6.909830056250527e-06, 'epoch': 3.5307517084282463, 'num_input_tokens_seen': 2419209}\n",
      "{'loss': 0.1105, 'grad_norm': 8.68903636932373, 'learning_rate': 6.2880275108177915e-06, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2499209}\n",
      "{'eval_loss': 0.25169071555137634, 'eval_overall_precision': 0.49569707401032703, 'eval_overall_recall': 0.6293494704992436, 'eval_overall_f1': 0.5545845059991114, 'eval_PER_precision': 0.44110479285134035, 'eval_PER_recall': 0.5895765472312704, 'eval_PER_f1': 0.504646840148699, 'eval_LOC_precision': 0.6285077951002227, 'eval_LOC_recall': 0.7681001633097442, 'eval_LOC_f1': 0.6913277804997551, 'eval_ORG_precision': 0.43951612903225806, 'eval_ORG_recall': 0.5677083333333334, 'eval_ORG_f1': 0.4954545454545455, 'eval_MISC_precision': 0.436036036036036, 'eval_MISC_recall': 0.5226781857451404, 'eval_MISC_f1': 0.4754420432220039, 'eval_runtime': 7.4021, 'eval_samples_per_second': 439.062, 'eval_steps_per_second': 3.512, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2499209}\n",
      "{'loss': 0.1153, 'grad_norm': 1.4882429838180542, 'learning_rate': 5.6824564766150724e-06, 'epoch': 3.7585421412300684, 'num_input_tokens_seen': 2576569}\n",
      "{'loss': 0.11, 'grad_norm': 2.6223196983337402, 'learning_rate': 5.095764961694923e-06, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2653561}\n",
      "{'eval_loss': 0.2487127035856247, 'eval_overall_precision': 0.5240036827568065, 'eval_overall_recall': 0.6696923852748361, 'eval_overall_f1': 0.5879574970484062, 'eval_PER_precision': 0.49429037520391517, 'eval_PER_recall': 0.6579804560260586, 'eval_PER_f1': 0.5645086166744294, 'eval_LOC_precision': 0.6364460562103355, 'eval_LOC_recall': 0.7642896026129559, 'eval_LOC_f1': 0.6945337620578778, 'eval_ORG_precision': 0.47885777045579353, 'eval_ORG_recall': 0.6488095238095238, 'eval_ORG_f1': 0.5510268562401264, 'eval_MISC_precision': 0.4412811387900356, 'eval_MISC_recall': 0.5356371490280778, 'eval_MISC_f1': 0.4839024390243903, 'eval_runtime': 7.3201, 'eval_samples_per_second': 443.985, 'eval_steps_per_second': 3.552, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2653561}\n",
      "{'loss': 0.1084, 'grad_norm': 4.575154781341553, 'learning_rate': 4.530518418775734e-06, 'epoch': 3.9863325740318905, 'num_input_tokens_seen': 2732649}\n",
      "{'loss': 0.0998, 'grad_norm': 3.136503219604492, 'learning_rate': 3.989188527169749e-06, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 2810839}\n",
      "{'eval_loss': 0.24894572794437408, 'eval_overall_precision': 0.526640719366528, 'eval_overall_recall': 0.659606656580938, 'eval_overall_f1': 0.5856716417910449, 'eval_PER_precision': 0.4866935483870968, 'eval_PER_recall': 0.6552660152008686, 'eval_PER_f1': 0.5585377140212865, 'eval_LOC_precision': 0.6538461538461539, 'eval_LOC_recall': 0.7495917256396298, 'eval_LOC_f1': 0.6984529546030941, 'eval_ORG_precision': 0.46774193548387094, 'eval_ORG_recall': 0.6257440476190477, 'eval_ORG_f1': 0.5353278166772756, 'eval_MISC_precision': 0.4676663542642924, 'eval_MISC_recall': 0.5388768898488121, 'eval_MISC_f1': 0.5007526342197692, 'eval_runtime': 7.2418, 'eval_samples_per_second': 448.784, 'eval_steps_per_second': 3.59, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 2810839}\n",
      "{'loss': 0.1052, 'grad_norm': 4.113900184631348, 'learning_rate': 3.4741423847583134e-06, 'epoch': 4.214123006833713, 'num_input_tokens_seen': 2888231}\n",
      "{'loss': 0.101, 'grad_norm': 2.4972357749938965, 'learning_rate': 2.9876321572751143e-06, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 2968263}\n",
      "{'eval_loss': 0.27344775199890137, 'eval_overall_precision': 0.4940898345153664, 'eval_overall_recall': 0.6675071440578249, 'eval_overall_f1': 0.5678535678535679, 'eval_PER_precision': 0.47577786530129973, 'eval_PER_recall': 0.6558089033659066, 'eval_PER_f1': 0.5514722666057977, 'eval_LOC_precision': 0.6263392857142858, 'eval_LOC_recall': 0.763745236799129, 'eval_LOC_f1': 0.6882511650723572, 'eval_ORG_precision': 0.42723263506063947, 'eval_ORG_recall': 0.5766369047619048, 'eval_ORG_f1': 0.49081697276757436, 'eval_MISC_precision': 0.4051246537396122, 'eval_MISC_recall': 0.6317494600431965, 'eval_MISC_f1': 0.4936708860759494, 'eval_runtime': 7.983, 'eval_samples_per_second': 407.113, 'eval_steps_per_second': 3.257, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 2968263}\n",
      "{'loss': 0.098, 'grad_norm': 2.037994384765625, 'learning_rate': 2.5317852301584642e-06, 'epoch': 4.4419134396355355, 'num_input_tokens_seen': 3044967}\n",
      "{'loss': 0.1003, 'grad_norm': 5.6931328773498535, 'learning_rate': 2.1085949060360654e-06, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3122231}\n",
      "{'eval_loss': 0.2650359570980072, 'eval_overall_precision': 0.5003177023764138, 'eval_overall_recall': 0.6617918977979492, 'eval_overall_f1': 0.5698364452163843, 'eval_PER_precision': 0.4626865671641791, 'eval_PER_recall': 0.6226927252985885, 'eval_PER_f1': 0.5308956260124972, 'eval_LOC_precision': 0.6329571106094808, 'eval_LOC_recall': 0.7632008709853021, 'eval_LOC_f1': 0.6920039486673247, 'eval_ORG_precision': 0.4566683964711988, 'eval_ORG_recall': 0.6547619047619048, 'eval_ORG_f1': 0.5380617548150413, 'eval_MISC_precision': 0.40705128205128205, 'eval_MISC_recall': 0.5485961123110151, 'eval_MISC_f1': 0.46734130634774607, 'eval_runtime': 7.7479, 'eval_samples_per_second': 419.47, 'eval_steps_per_second': 3.356, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3122231}\n",
      "{'loss': 0.1011, 'grad_norm': 0.854559063911438, 'learning_rate': 1.7199116885197996e-06, 'epoch': 4.669703872437358, 'num_input_tokens_seen': 3200151}\n",
      "{'loss': 0.0946, 'grad_norm': 6.0594258308410645, 'learning_rate': 1.367435190424261e-06, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3278631}\n",
      "{'eval_loss': 0.25607994198799133, 'eval_overall_precision': 0.5084055017829853, 'eval_overall_recall': 0.6710371491006892, 'eval_overall_f1': 0.5785088037098762, 'eval_PER_precision': 0.47310126582278483, 'eval_PER_recall': 0.6492942453854506, 'eval_PER_f1': 0.5473684210526316, 'eval_LOC_precision': 0.6207674943566591, 'eval_LOC_recall': 0.7485029940119761, 'eval_LOC_f1': 0.6786771964461995, 'eval_ORG_precision': 0.4628937533368927, 'eval_ORG_recall': 0.6450892857142857, 'eval_ORG_f1': 0.5390115013988187, 'eval_MISC_precision': 0.4482200647249191, 'eval_MISC_recall': 0.5982721382289417, 'eval_MISC_f1': 0.5124884366327475, 'eval_runtime': 7.4121, 'eval_samples_per_second': 438.473, 'eval_steps_per_second': 3.508, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3278631}\n",
      "{'loss': 0.1027, 'grad_norm': 3.725776195526123, 'learning_rate': 1.0527067017923654e-06, 'epoch': 4.89749430523918, 'num_input_tokens_seen': 3357111}\n",
      "{'loss': 0.0937, 'grad_norm': 3.5726892948150635, 'learning_rate': 7.771024502261526e-07, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3436536}\n",
      "{'eval_loss': 0.2513583302497864, 'eval_overall_precision': 0.5101146759438216, 'eval_overall_recall': 0.6654899983190452, 'eval_overall_f1': 0.5775346462436178, 'eval_PER_precision': 0.4728806749698674, 'eval_PER_recall': 0.6389793702497285, 'eval_PER_f1': 0.543523435696144, 'eval_LOC_precision': 0.6351471900089206, 'eval_LOC_recall': 0.7751769188894937, 'eval_LOC_f1': 0.698210345672959, 'eval_ORG_precision': 0.44842562432138977, 'eval_ORG_recall': 0.6145833333333334, 'eval_ORG_f1': 0.5185185185185186, 'eval_MISC_precision': 0.4478114478114478, 'eval_MISC_recall': 0.5745140388768899, 'eval_MISC_f1': 0.5033112582781457, 'eval_runtime': 7.8299, 'eval_samples_per_second': 415.077, 'eval_steps_per_second': 3.321, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3436536}\n",
      "{'loss': 0.0943, 'grad_norm': 8.32351303100586, 'learning_rate': 5.418275829936537e-07, 'epoch': 5.125284738041002, 'num_input_tokens_seen': 3516360}\n",
      "{'loss': 0.0827, 'grad_norm': 3.1424458026885986, 'learning_rate': 3.4791089722651437e-07, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3592952}\n",
      "{'eval_loss': 0.2543761134147644, 'eval_overall_precision': 0.5187695516162669, 'eval_overall_recall': 0.6690200033619096, 'eval_overall_f1': 0.5843917480361207, 'eval_PER_precision': 0.4911003236245955, 'eval_PER_recall': 0.6590662323561346, 'eval_PER_f1': 0.5628187297171997, 'eval_LOC_precision': 0.6413141314131413, 'eval_LOC_recall': 0.7757212847033206, 'eval_LOC_f1': 0.7021433850702142, 'eval_ORG_precision': 0.4490022172949002, 'eval_ORG_recall': 0.6026785714285714, 'eval_ORG_f1': 0.5146124523506987, 'eval_MISC_precision': 0.45229982964224874, 'eval_MISC_recall': 0.5734341252699784, 'eval_MISC_f1': 0.5057142857142857, 'eval_runtime': 7.3862, 'eval_samples_per_second': 440.013, 'eval_steps_per_second': 3.52, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3592952}\n",
      "{'loss': 0.0912, 'grad_norm': 4.330774784088135, 'learning_rate': 1.9620034125190645e-07, 'epoch': 5.353075170842825, 'num_input_tokens_seen': 3672664}\n",
      "{'loss': 0.0902, 'grad_norm': 5.746049404144287, 'learning_rate': 8.735930673024806e-08, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 3750152}\n",
      "{'eval_loss': 0.2558786869049072, 'eval_overall_precision': 0.5132937532266392, 'eval_overall_recall': 0.6685157169272147, 'eval_overall_f1': 0.5807111046214499, 'eval_PER_precision': 0.4838318512530315, 'eval_PER_recall': 0.6498371335504886, 'eval_PER_f1': 0.5546802594995365, 'eval_LOC_precision': 0.6357941834451901, 'eval_LOC_recall': 0.773543821448013, 'eval_LOC_f1': 0.6979371316306483, 'eval_ORG_precision': 0.44844253490870034, 'eval_ORG_recall': 0.6212797619047619, 'eval_ORG_f1': 0.5208983156581409, 'eval_MISC_precision': 0.44519966015293116, 'eval_MISC_recall': 0.5658747300215983, 'eval_MISC_f1': 0.4983357108892059, 'eval_runtime': 7.539, 'eval_samples_per_second': 431.094, 'eval_steps_per_second': 3.449, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 3750152}\n",
      "{'loss': 0.102, 'grad_norm': 1.1388849020004272, 'learning_rate': 2.1863727812254653e-08, 'epoch': 5.5808656036446465, 'num_input_tokens_seen': 3825400}\n",
      "{'loss': 0.0938, 'grad_norm': 10.461612701416016, 'learning_rate': 0.0, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n",
      "{'eval_loss': 0.25559210777282715, 'eval_overall_precision': 0.5112656109179864, 'eval_overall_recall': 0.6675071440578249, 'eval_overall_f1': 0.5790317876932051, 'eval_PER_precision': 0.4804514308746473, 'eval_PER_recall': 0.6471226927252985, 'eval_PER_f1': 0.5514688873467499, 'eval_LOC_precision': 0.6338846669646848, 'eval_LOC_recall': 0.7719107240065324, 'eval_LOC_f1': 0.6961217476681394, 'eval_ORG_precision': 0.4492208490059108, 'eval_ORG_recall': 0.6220238095238095, 'eval_ORG_f1': 0.5216848673946958, 'eval_MISC_precision': 0.44191919191919193, 'eval_MISC_recall': 0.5669546436285097, 'eval_MISC_f1': 0.4966887417218543, 'eval_runtime': 7.5027, 'eval_samples_per_second': 433.178, 'eval_steps_per_second': 3.465, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n",
      "{'train_runtime': 430.9478, 'train_samples_per_second': 185.637, 'train_steps_per_second': 11.602, 'train_loss': 0.19429620170593262, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.19429620170593262, metrics={'train_runtime': 430.9478, 'train_samples_per_second': 185.637, 'train_steps_per_second': 11.602, 'train_loss': 0.19429620170593262, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:32:11.555155Z",
     "start_time": "2024-12-07T00:30:09.293281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results_l12 = trainer.evaluate(Dataset(load_from_disk('data/test'), tokenizer_name='xlm-v'), metric_key_prefix='transfer')\n",
    "test_results_l12"
   ],
   "id": "d205289b25ad7bd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transfer_loss': 0.6994850039482117, 'transfer_overall_precision': 0.07787755102040816, 'transfer_overall_recall': 0.19928974305410488, 'transfer_overall_f1': 0.11199154780771264, 'transfer_PER_precision': 0.05136986301369863, 'transfer_PER_recall': 0.15996122152205525, 'transfer_PER_f1': 0.07776599505125485, 'transfer_LOC_precision': 0.12736799677549376, 'transfer_LOC_recall': 0.3463013698630137, 'transfer_LOC_f1': 0.18623839693531755, 'transfer_ORG_precision': 0.08954361640670133, 'transfer_ORG_recall': 0.3891213389121339, 'transfer_ORG_f1': 0.1455854727614277, 'transfer_MISC_precision': 0.0516096065406234, 'transfer_MISC_recall': 0.07331591173054587, 'transfer_MISC_f1': 0.060576980747316024, 'transfer_runtime': 120.9374, 'transfer_samples_per_second': 74.104, 'transfer_steps_per_second': 0.587, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 3906776}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transfer_loss': 0.6994850039482117,\n",
       " 'transfer_overall_precision': 0.07787755102040816,\n",
       " 'transfer_overall_recall': 0.19928974305410488,\n",
       " 'transfer_overall_f1': 0.11199154780771264,\n",
       " 'transfer_PER_precision': 0.05136986301369863,\n",
       " 'transfer_PER_recall': 0.15996122152205525,\n",
       " 'transfer_PER_f1': 0.07776599505125485,\n",
       " 'transfer_LOC_precision': 0.12736799677549376,\n",
       " 'transfer_LOC_recall': 0.3463013698630137,\n",
       " 'transfer_LOC_f1': 0.18623839693531755,\n",
       " 'transfer_ORG_precision': 0.08954361640670133,\n",
       " 'transfer_ORG_recall': 0.3891213389121339,\n",
       " 'transfer_ORG_f1': 0.1455854727614277,\n",
       " 'transfer_MISC_precision': 0.0516096065406234,\n",
       " 'transfer_MISC_recall': 0.07331591173054587,\n",
       " 'transfer_MISC_f1': 0.060576980747316024,\n",
       " 'transfer_runtime': 120.9374,\n",
       " 'transfer_samples_per_second': 74.104,\n",
       " 'transfer_steps_per_second': 0.587,\n",
       " 'epoch': 5.694760820045558,\n",
       " 'num_input_tokens_seen': 3906776}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T00:58:42.767237Z",
     "start_time": "2024-12-07T00:58:42.757400Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_from_disk('data/valid')",
   "id": "a21ff6ac625d061c",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:04:27.206559Z",
     "start_time": "2024-12-07T01:04:27.197515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_idx = 3\n",
    "ner_tags = torch.as_tensor(dataset[test_idx]['xlm-v_sub_token_ner_tags'])\n",
    "tokens = torch.as_tensor(dataset[test_idx]['xlm-v_sub_tokens'])\n",
    "print('Text:', ' '.join(dataset[test_idx]['tokens']))\n",
    "print('Ents:', xlm_tok.decode(tokens[ner_tags > 0]))\n",
    "print()"
   ],
   "id": "1f7592490dabd5aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Their stay on top , though , may be short-lived as title rivals Essex , Derbyshire and Surrey all closed in on victory while Kent made up for lost time in their rain-affected match against Nottinghamshire .\n",
      "Ents: Essex Derbyshire Surrey Kent Nottinghamshire\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6aeb50a791f0eaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
