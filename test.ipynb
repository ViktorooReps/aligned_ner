{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:59.535794Z",
     "start_time": "2024-12-06T19:35:54.952353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import BatchEncoding, PreTrainedTokenizer, AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers.data import data_collator\n",
    "\n",
    "from modelling_xlm_roberta import XLMRobertaForTokenClassification\n",
    "import nervaluate\n",
    "\n",
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "from typing import Iterable\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda'\n",
    "model_dtype = torch.bfloat16\n",
    "torch.cuda.get_device_name(0)"
   ],
   "id": "164bfe6522ca666c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA H100 80GB HBM3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Test that layer cutting works",
   "id": "bd4e31a4b6b090d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:25:33.985745Z",
     "start_time": "2024-12-06T19:25:33.037112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_test = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base')\n",
    "model_test"
   ],
   "id": "50cd8944790c35f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(901629, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:25:34.462156Z",
     "start_time": "2024-12-06T19:25:33.986864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_test = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base', skip_last_layer=True)\n",
    "model_test"
   ],
   "id": "45dbf4a4718b4f0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(901629, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-10): 11 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Works! Passing `skip_last_layer=True` removes the last layer in the transformer stack (11 x XLMRobertaLayer instead of 12 x XLMRobertaLayer)",
   "id": "d91e348b9d48ece2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Train models on the downstream tagging task and evaluate the knowledge transfer to a different language\n",
    "For this we will use CoNLL 2003 corpus (`eriktks/conll2003`, 14k examples) to train the model and Afrikaans NER Corpus (`nwu-ctext/afrikaans_ner_corpus`, 9k examples) to test the model. The validation is done over CoNLL 2003, only the final scores for Afrikaans are reported."
   ],
   "id": "9af1cd678fa696d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.077613Z",
     "start_time": "2024-12-06T19:25:52.307681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = load_dataset('eriktks/conll2003', split='train')\n",
    "valid_dataset = load_dataset('eriktks/conll2003', split='validation')\n",
    "test_dataset = load_dataset('nwu-ctext/afrikaans_ner_corpus', split='train')"
   ],
   "id": "19ee1cb470c3ca97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c5a44f9cbdb4889a89e7eb308a85d1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4736511aa72f42b08d8ba4a04bcd5468"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdedf3b38df447b692226e9790d16d5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62bddc30e9874a37b9f8f1853e20db4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2dc63aba5c445479460540c28d695db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7de8dc6a4acd4677a365a454f564dfa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.82k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4edd1e76c09740f795fd81a72e19166a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/945k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e475653da4524796a1931c3eaf605e64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e080aef0b884e5395e7bf108857f052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make sure that the labelling scheme is identical across datasets",
   "id": "ecafcb621612d84f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.081223Z",
     "start_time": "2024-12-06T19:26:20.078555Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset.features['ner_tags']",
   "id": "668a8c6cfaac7811",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.084101Z",
     "start_time": "2024-12-06T19:26:20.081694Z"
    }
   },
   "cell_type": "code",
   "source": "valid_dataset.features['ner_tags']",
   "id": "432d9997a6a8bcf1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:20.086733Z",
     "start_time": "2024-12-06T19:26:20.084795Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset.features['ner_tags']",
   "id": "8c160d6214600da3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['OUT', 'B-PERS', 'I-PERS', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The names are a bit different, but otherwise the schemes are identical",
   "id": "d61fbac113d2c666"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Convert word-level tags to subtoken-level tags",
   "id": "2e089cee56f48462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:30:00.398308Z",
     "start_time": "2024-12-06T19:29:56.297177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xlm_tok = AutoTokenizer.from_pretrained('facebook/xlm-v-base')\n",
    "xlm_tok_name = 'xlm-v'\n",
    "\n",
    "xlm_tok('test <mask> test', return_offsets_mapping=True)"
   ],
   "id": "7c3f74ba028a74e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1340, 901628, 1340, 2], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 4), (4, 11), (11, 16), (0, 0)]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:37:07.503136Z",
     "start_time": "2024-12-06T19:37:07.499263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for reference\n",
    "ner_tags_scheme = np.array(['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
    "ner_tags_ext    =          [  0,       2,       2,       4,       4,       6,       6,        8,        8]\n",
    "# the ext is used when we need to split one word into multiple sub tokens"
   ],
   "id": "cfb59f07b44af84f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:29.957380Z",
     "start_time": "2024-12-06T19:26:24.077956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(example: dict, tokenizer: PreTrainedTokenizer, tokenizer_name: str, max_length: int = 512) -> dict:\n",
    "    ner_tags: list[int] = example['ner_tags']\n",
    "    example_words: list[str] = example['tokens']\n",
    "    text = ' '.join(example_words)\n",
    "    \n",
    "    # map words to positions in text\n",
    "    word_positions: list[int] = example.get('word_positions', [])\n",
    "    \n",
    "    if len(word_positions) != len(example_words):\n",
    "        text_iterator = 0\n",
    "        for word in example_words:\n",
    "            while text[text_iterator:text_iterator + len(word)] != word:\n",
    "                text_iterator += 1\n",
    "                assert text_iterator < len(text)\n",
    "            \n",
    "            word_positions.append(text_iterator)\n",
    "    \n",
    "    encoding: BatchEncoding = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=max_length)\n",
    "    num_sub_tokens = len(encoding.offset_mapping)\n",
    "    \n",
    "    sub_token_iterator = 0\n",
    "    sub_token_ner_tags: list[int] = []\n",
    "    for word_id, ner_tag in enumerate(ner_tags):\n",
    "        word_start = word_positions[word_id]\n",
    "        word_end = word_start + len(example_words[word_id])\n",
    "        \n",
    "        # there may be some empty space between words. the sub tokens that include this empty space receive O label\n",
    "        # we compare with the end ([1]) to ensure that 0-length tokens are labelled as O (for example <CLS>)\n",
    "        while sub_token_iterator < num_sub_tokens and  encoding.offset_mapping[sub_token_iterator][1] <= word_start:\n",
    "            if encoding.offset_mapping[sub_token_iterator][1] - encoding.offset_mapping[sub_token_iterator][0] == 0:\n",
    "                # set to -100 for special tokens like <CLS>\n",
    "                sub_token_ner_tags.append(-100)\n",
    "            else:\n",
    "                sub_token_ner_tags.append(0)  # 0 = O\n",
    "            sub_token_iterator += 1\n",
    "            \n",
    "        ext_tag = ner_tags_ext[ner_tag]\n",
    "        \n",
    "        if sub_token_iterator < num_sub_tokens:\n",
    "            # the first sub token of a word receives original label, the rest receive extended label\n",
    "            sub_token_ner_tags.append(ner_tag)\n",
    "            sub_token_iterator += 1\n",
    "        \n",
    "        # again, we need to be careful about 0-length tokens, so we compare start ([0]) with the word end\n",
    "        while sub_token_iterator < num_sub_tokens and encoding.offset_mapping[sub_token_iterator][0] < word_end:\n",
    "            \n",
    "            # there is a weird quirk with transformers tokenizers: <SEP> token has (0, 0) offset \n",
    "            #   regardless of its real position, see https://github.com/huggingface/transformers/issues/35125\n",
    "            if encoding.offset_mapping[sub_token_iterator][1] - encoding.offset_mapping[sub_token_iterator][0] == 0:\n",
    "                sub_token_ner_tags.append(-100)\n",
    "            else:\n",
    "                sub_token_ner_tags.append(ext_tag)\n",
    "                \n",
    "            sub_token_iterator += 1\n",
    "    \n",
    "    # any tokens at the end (like <SEP>) receive O tokens\n",
    "    while sub_token_iterator < num_sub_tokens:\n",
    "        sub_token_iterator += 1\n",
    "        sub_token_ner_tags.append(0)\n",
    "        \n",
    "    return {\n",
    "        'word_positions': word_positions,\n",
    "        f'{tokenizer_name}_sub_tokens': encoding.input_ids,\n",
    "        f'{tokenizer_name}_sub_token_offsets': encoding.offset_mapping,\n",
    "        f'{tokenizer_name}_sub_token_ner_tags': sub_token_ner_tags,\n",
    "        'length': len(encoding.offset_mapping)\n",
    "    }\n",
    "\n",
    "tokenize_fn = partial(tokenize, tokenizer=xlm_tok, tokenizer_name=xlm_tok_name, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn)\n",
    "valid_dataset = valid_dataset.map(tokenize_fn)\n",
    "test_dataset = test_dataset.map(tokenize_fn)"
   ],
   "id": "21f16632e08f1c6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4840dc171de646ba9f546303a66f89b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd96d6a899b848d7ad6ff057fd606e30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "383aed25e5774537ad536fa5b6cc06f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:26:29.997429Z",
     "start_time": "2024-12-06T19:26:29.958462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for test_idx in range(25):\n",
    "    ner_tags = torch.as_tensor(train_dataset[test_idx]['xlm-v_sub_token_ner_tags'])\n",
    "    tokens = torch.as_tensor(train_dataset[test_idx]['xlm-v_sub_tokens'])\n",
    "    print('Text:', ' '.join(train_dataset[test_idx]['tokens']))\n",
    "    print('Ents:', xlm_tok.decode(tokens[ner_tags > 0]))\n",
    "    print()"
   ],
   "id": "d1bc289c17bf712c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: EU rejects German call to boycott British lamb .\n",
      "Ents: EU German British\n",
      "\n",
      "Text: Peter Blackburn\n",
      "Ents: Peter Blackburn\n",
      "\n",
      "Text: BRUSSELS 1996-08-22\n",
      "Ents: BRUSSELS\n",
      "\n",
      "Text: The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
      "Ents: European Commission German British\n",
      "\n",
      "Text: Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .\n",
      "Ents: Germany European Union Werner Zwingmann Britain\n",
      "\n",
      "Text: \" We do n't support any such recommendation because we do n't see any grounds for it , \" the Commission 's chief spokesman Nikolaus van der Pas told a news briefing .\n",
      "Ents: Commission Nikolaus van der Pas\n",
      "\n",
      "Text: He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .\n",
      "Ents: European Union\n",
      "\n",
      "Text: He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .\n",
      "Ents: EU Franz Fischler\n",
      "\n",
      "Text: Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease .\n",
      "Ents: Fischler EU-wide Britain France Bovine Spongiform Encephalopathy BSE\n",
      "\n",
      "Text: But Fischler agreed to review his proposal after the EU 's standing veterinary committee , mational animal health officials , questioned if such action was justified as there was only a slight risk to human health .\n",
      "Ents: Fischler EU\n",
      "\n",
      "Text: Spanish Farm Minister Loyola de Palacio had earlier accused Fischler at an EU farm ministers ' meeting of causing unjustified alarm through \" dangerous generalisation . \"\n",
      "Ents: Spanish Loyola de Palacio Fischler EU\n",
      "\n",
      "Text: .\n",
      "Ents: \n",
      "\n",
      "Text: Only France and Britain backed Fischler 's proposal .\n",
      "Ents: France Britain Fischler\n",
      "\n",
      "Text: The EU 's scientific veterinary and multidisciplinary committees are due to re-examine the issue early next month and make recommendations to the senior veterinary officials .\n",
      "Ents: EU\n",
      "\n",
      "Text: Sheep have long been known to contract scrapie , a brain-wasting disease similar to BSE which is believed to have been transferred to cattle through feed containing animal waste .\n",
      "Ents: BSE\n",
      "\n",
      "Text: British farmers denied on Thursday there was any danger to human health from their sheep , but expressed concern that German government advice to consumers to avoid British lamb might influence consumers across Europe .\n",
      "Ents: British German British Europe\n",
      "\n",
      "Text: \" What we have to be extremely careful of is how other countries are going to take Germany 's lead , \" Welsh National Farmers ' Union ( NFU ) chairman John Lloyd Jones said on BBC radio .\n",
      "Ents: Germany Welsh National Farmers'Union NFU John Lloyd Jones BBC radio\n",
      "\n",
      "Text: Bonn has led efforts to protect public health after consumer confidence collapsed in March after a British report suggested humans could contract an illness similar to mad cow disease by eating contaminated beef .\n",
      "Ents: Bonn British\n",
      "\n",
      "Text: Germany imported 47,600 sheep from Britain last year , nearly half of total imports .\n",
      "Ents: Germany Britain\n",
      "\n",
      "Text: It brought in 4,275 tonnes of British mutton , some 10 percent of overall imports .\n",
      "Ents: British\n",
      "\n",
      "Text: Rare Hendrix song draft sells for almost $ 17,000 .\n",
      "Ents: Hendrix\n",
      "\n",
      "Text: LONDON 1996-08-22\n",
      "Ents: LONDON\n",
      "\n",
      "Text: A rare early handwritten draft of a song by U.S. guitar legend Jimi Hendrix was sold for almost $ 17,000 on Thursday at an auction of some of the late musician 's favourite possessions .\n",
      "Ents: U.S. Jimi Hendrix\n",
      "\n",
      "Text: A Florida restaurant paid 10,925 pounds ( $ 16,935 ) for the draft of \" Ai n't no telling \" , which Hendrix penned on a piece of London hotel stationery in late 1966 .\n",
      "Ents: Florida Ain't no telling Hendrix London\n",
      "\n",
      "Text: At the end of a January 1967 concert in the English city of Nottingham he threw the sheet of paper into the audience , where it was retrieved by a fan .\n",
      "Ents: English Nottingham\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looks nice!",
   "id": "9234e8f0ab28fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:28:44.626907Z",
     "start_time": "2024-12-06T19:28:44.374015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset.save_to_disk('data/train')\n",
    "valid_dataset.save_to_disk('data/valid')\n",
    "test_dataset.save_to_disk('data/test')"
   ],
   "id": "8d7920ea056c2596",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "485329834fd7465aa6ec2087457d8894"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98d7310b332843b4a4ec9795c7ef1fdf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79b05ad9ab604913a8874bdecc8ba918"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:36:09.618274Z",
     "start_time": "2024-12-06T19:36:09.612413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, examples: Iterable[dict], tokenizer_name: str):\n",
    "        self.input_ids = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for example in examples:\n",
    "            self.input_ids.append(torch.as_tensor(example[f'{tokenizer_name}_sub_tokens']))\n",
    "            self.labels.append(torch.as_tensor(example[f'{tokenizer_name}_sub_token_ner_tags']))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "def collate_fn(inputs: list[(Tensor, Tensor)], *, pad_token: int) -> dict:\n",
    "    all_input_ids = []\n",
    "    all_labels = []\n",
    "    for input_ids, labels in inputs:\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    input_ids = pad_sequence(all_input_ids, batch_first=True, padding_value=pad_token)\n",
    "    \n",
    "    batch_size, seq_length = input_ids.shape\n",
    "\n",
    "    # do not attend to pad and pad does not attend to anything\n",
    "    pad_mask = (input_ids != pad_token)\n",
    "    attention_mask = (pad_mask.reshape(batch_size, 1, -1) != pad_mask.reshape(batch_size, -1, 1))\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': pad_sequence(all_labels, batch_first=True, padding_value=-100),\n",
    "        'attention_mask': attention_mask\n",
    "    }"
   ],
   "id": "2bbb670d6122a3f5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:54:26.534251Z",
     "start_time": "2024-12-06T19:54:26.528257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_ner_metrics(eval_pred) -> dict:\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    padding = (labels < 0)\n",
    "    \n",
    "    predictions = predictions[~padding]\n",
    "    labels = labels[~padding]\n",
    "\n",
    "    predictions = ner_tags_scheme[predictions]\n",
    "    labels = ner_tags_scheme[labels]\n",
    "\n",
    "    evaluator = nervaluate.Evaluator([labels], [predictions], tags=['PER', 'LOC', 'ORG', 'MISC'], loader='list')\n",
    "    results, results_per_tag, _, _ = evaluator.evaluate()\n",
    "\n",
    "    overall_metrics = results[\"strict\"]\n",
    "    \n",
    "    metrics = {\n",
    "        'overall_precision': overall_metrics['precision'],\n",
    "        'overall_recall': overall_metrics['recall'],\n",
    "        'overall_f1': overall_metrics['f1'],\n",
    "    }\n",
    "    \n",
    "    for tag, tag_metrics in results_per_tag.items():\n",
    "        metrics[f'{tag}_precision'] = tag_metrics['strict']['precision']\n",
    "        metrics[f'{tag}_recall'] = tag_metrics['strict']['recall']\n",
    "        metrics[f'{tag}_f1'] = tag_metrics['strict']['f1']\n",
    "\n",
    "    # Return desired metrics\n",
    "    return metrics"
   ],
   "id": "3da5ff8b55ce26e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Train a conventional model",
   "id": "c9559c9f274e9c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:54:27.228148Z",
     "start_time": "2024-12-06T19:54:27.223939Z"
    }
   },
   "cell_type": "code",
   "source": "n_run = 0",
   "id": "4a4988357b4e9d66",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:17:56.797758Z",
     "start_time": "2024-12-06T20:09:13.749168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_run += 1\n",
    "model = XLMRobertaForTokenClassification.from_pretrained('facebook/xlm-v-base', num_labels=9)\n",
    "xlm_tok = AutoTokenizer.from_pretrained('facebook/xlm-v-base')\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=f'xlm-v-base-finetuned-l12-conll03/{datetime.now().strftime(\"%m-%d\")}/{n_run}',\n",
    "        overwrite_output_dir=True,\n",
    "        eval_strategy='steps',\n",
    "        eval_delay=0.001,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=128,\n",
    "        learning_rate=2e-5,\n",
    "        max_steps=10000,\n",
    "        lr_scheduler_type='cosine',\n",
    "        lr_scheduler_kwargs={ \"num_cycles\": 1 },\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=250,\n",
    "        bf16=True,\n",
    "        eval_steps=500,\n",
    "        dataloader_num_workers=4,\n",
    "        torch_compile=True,\n",
    "        include_num_input_tokens_seen=True,\n",
    "        disable_tqdm=True\n",
    "    ),\n",
    "    data_collator=partial(collate_fn, pad_token=xlm_tok.pad_token_id),\n",
    "    train_dataset=Dataset(load_from_disk('data/train'), tokenizer_name='xlm-v'),\n",
    "    eval_dataset=Dataset(load_from_disk('data/valid'), tokenizer_name='xlm-v'),\n",
    "    compute_metrics=compute_ner_metrics\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "c13273fe9f7aff09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2377, 'grad_norm': 7.369006156921387, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.05694760820045558, 'num_input_tokens_seen': 42848}\n",
      "{'loss': 2.1255, 'grad_norm': 21.421642303466797, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.11389521640091116, 'num_input_tokens_seen': 85568}\n",
      "{'loss': 1.6144, 'grad_norm': 15.64748764038086, 'learning_rate': 3e-06, 'epoch': 0.17084282460136674, 'num_input_tokens_seen': 132768}\n",
      "{'loss': 1.2593, 'grad_norm': 5.6847381591796875, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 174496}\n",
      "{'eval_loss': 1.1656874418258667, 'eval_overall_precision': 0.0022560631697687537, 'eval_overall_recall': 0.0006723819129265423, 'eval_overall_f1': 0.001036001036001036, 'eval_PER_precision': 0.0023937761819269898, 'eval_PER_recall': 0.002171552660152009, 'eval_PER_f1': 0.0022772559066325075, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 3.342, 'eval_samples_per_second': 972.475, 'eval_steps_per_second': 7.78, 'epoch': 0.22779043280182232, 'num_input_tokens_seen': 174496}\n",
      "{'loss': 1.1183, 'grad_norm': 4.376546382904053, 'learning_rate': 5e-06, 'epoch': 0.2847380410022779, 'num_input_tokens_seen': 217536}\n",
      "{'loss': 1.046, 'grad_norm': 3.9137020111083984, 'learning_rate': 6e-06, 'epoch': 0.3416856492027335, 'num_input_tokens_seen': 260224}\n",
      "{'loss': 0.9869, 'grad_norm': 3.6268808841705322, 'learning_rate': 7e-06, 'epoch': 0.39863325740318906, 'num_input_tokens_seen': 302368}\n",
      "{'loss': 0.9882, 'grad_norm': 4.475965976715088, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 344128}\n",
      "{'eval_loss': 0.936316728591919, 'eval_overall_precision': 0.00784313725490196, 'eval_overall_recall': 0.0006723819129265423, 'eval_overall_f1': 0.0012385818238117355, 'eval_PER_precision': 0.008968609865470852, 'eval_PER_recall': 0.002171552660152009, 'eval_PER_f1': 0.003496503496503497, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 1.6706, 'eval_samples_per_second': 1945.452, 'eval_steps_per_second': 15.564, 'epoch': 0.45558086560364464, 'num_input_tokens_seen': 344128}\n",
      "{'loss': 0.9235, 'grad_norm': 9.92320442199707, 'learning_rate': 9e-06, 'epoch': 0.5125284738041003, 'num_input_tokens_seen': 387040}\n",
      "{'loss': 0.8368, 'grad_norm': 8.084832191467285, 'learning_rate': 1e-05, 'epoch': 0.5694760820045558, 'num_input_tokens_seen': 428832}\n",
      "{'loss': 0.7287, 'grad_norm': 3.356531858444214, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.6264236902050114, 'num_input_tokens_seen': 472032}\n",
      "{'loss': 0.6592, 'grad_norm': 2.8247783184051514, 'learning_rate': 1.2e-05, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 514784}\n",
      "{'eval_loss': 0.6505380868911743, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0, 'eval_PER_precision': 0.0, 'eval_PER_recall': 0.0, 'eval_PER_f1': 0, 'eval_LOC_precision': 0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 0.9091, 'eval_samples_per_second': 3574.855, 'eval_steps_per_second': 28.599, 'epoch': 0.683371298405467, 'num_input_tokens_seen': 514784}\n",
      "{'loss': 0.6468, 'grad_norm': 6.281939506530762, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.7403189066059226, 'num_input_tokens_seen': 558208}\n",
      "{'loss': 0.6345, 'grad_norm': 6.667145252227783, 'learning_rate': 1.4e-05, 'epoch': 0.7972665148063781, 'num_input_tokens_seen': 604704}\n",
      "{'loss': 0.6307, 'grad_norm': 2.2617733478546143, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.8542141230068337, 'num_input_tokens_seen': 646656}\n",
      "{'loss': 0.5687, 'grad_norm': 4.9025163650512695, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 690144}\n",
      "{'eval_loss': 0.6059278249740601, 'eval_overall_precision': 0.032004197271773345, 'eval_overall_recall': 0.04101529668851908, 'eval_overall_f1': 0.035953731673174685, 'eval_PER_precision': 0.053863134657836646, 'eval_PER_recall': 0.13246471226927253, 'eval_PER_f1': 0.07658505963590709, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 11.2589, 'eval_samples_per_second': 288.662, 'eval_steps_per_second': 2.309, 'epoch': 0.9111617312072893, 'num_input_tokens_seen': 690144}\n",
      "{'loss': 0.5956, 'grad_norm': 4.215907096862793, 'learning_rate': 1.7e-05, 'epoch': 0.9681093394077449, 'num_input_tokens_seen': 734816}\n",
      "{'loss': 0.5331, 'grad_norm': 3.006859302520752, 'learning_rate': 1.8e-05, 'epoch': 1.0250569476082005, 'num_input_tokens_seen': 775372}\n",
      "{'loss': 0.5363, 'grad_norm': 2.197056293487549, 'learning_rate': 1.9e-05, 'epoch': 1.082004555808656, 'num_input_tokens_seen': 821676}\n",
      "{'loss': 0.5422, 'grad_norm': 5.652753829956055, 'learning_rate': 2e-05, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 862700}\n",
      "{'eval_loss': 0.554653525352478, 'eval_overall_precision': 0.0472550382209868, 'eval_overall_recall': 0.06858295511850732, 'eval_overall_f1': 0.05595556469862169, 'eval_PER_precision': 0.08605341246290801, 'eval_PER_recall': 0.22041259500542887, 'eval_PER_f1': 0.12378048780487806, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.001483679525222552, 'eval_ORG_recall': 0.001488095238095238, 'eval_ORG_f1': 0.0014858841010401188, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 12.7613, 'eval_samples_per_second': 254.677, 'eval_steps_per_second': 2.037, 'epoch': 1.1389521640091116, 'num_input_tokens_seen': 862700}\n",
      "{'loss': 0.4933, 'grad_norm': 1.4419972896575928, 'learning_rate': 1.999390827019096e-05, 'epoch': 1.1958997722095672, 'num_input_tokens_seen': 905772}\n",
      "{'loss': 0.4839, 'grad_norm': 2.5666370391845703, 'learning_rate': 1.9975640502598243e-05, 'epoch': 1.2528473804100229, 'num_input_tokens_seen': 947372}\n",
      "{'loss': 0.4864, 'grad_norm': 2.9290030002593994, 'learning_rate': 1.9945218953682736e-05, 'epoch': 1.3097949886104785, 'num_input_tokens_seen': 988716}\n",
      "{'loss': 0.4685, 'grad_norm': 3.7405922412872314, 'learning_rate': 1.9902680687415704e-05, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 1030796}\n",
      "{'eval_loss': 0.47174444794654846, 'eval_overall_precision': 0.11931540342298289, 'eval_overall_recall': 0.16406118675407633, 'eval_overall_f1': 0.1381555665652205, 'eval_PER_precision': 0.2512629619781973, 'eval_PER_recall': 0.5130293159609121, 'eval_PER_f1': 0.33731929323576654, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0, 'eval_ORG_precision': 0.017454954954954954, 'eval_ORG_recall': 0.023065476190476192, 'eval_ORG_f1': 0.01987179487179487, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 11.8479, 'eval_samples_per_second': 274.309, 'eval_steps_per_second': 2.194, 'epoch': 1.366742596810934, 'num_input_tokens_seen': 1030796}\n",
      "{'loss': 0.4285, 'grad_norm': 3.4048562049865723, 'learning_rate': 1.9848077530122083e-05, 'epoch': 1.4236902050113895, 'num_input_tokens_seen': 1074316}\n",
      "{'loss': 0.4222, 'grad_norm': 3.580545663833618, 'learning_rate': 1.9781476007338058e-05, 'epoch': 1.4806378132118452, 'num_input_tokens_seen': 1118220}\n",
      "{'loss': 0.3913, 'grad_norm': 3.509700298309326, 'learning_rate': 1.9702957262759964e-05, 'epoch': 1.5375854214123006, 'num_input_tokens_seen': 1161676}\n",
      "{'loss': 0.3814, 'grad_norm': 6.208134174346924, 'learning_rate': 1.961261695938319e-05, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1203756}\n",
      "{'eval_loss': 0.40291115641593933, 'eval_overall_precision': 0.24872115493918381, 'eval_overall_recall': 0.36779290637081863, 'eval_overall_f1': 0.29675844296758447, 'eval_PER_precision': 0.2096378146101903, 'eval_PER_recall': 0.3707926167209555, 'eval_PER_f1': 0.26784313725490194, 'eval_LOC_precision': 0.42467248908296945, 'eval_LOC_recall': 0.6352749047359826, 'eval_LOC_f1': 0.509051254089422, 'eval_ORG_precision': 0.17576703068122726, 'eval_ORG_recall': 0.25148809523809523, 'eval_ORG_f1': 0.20691766146311602, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 10.9212, 'eval_samples_per_second': 297.586, 'eval_steps_per_second': 2.381, 'epoch': 1.5945330296127562, 'num_input_tokens_seen': 1203756}\n",
      "{'loss': 0.3474, 'grad_norm': 6.05137825012207, 'learning_rate': 1.9510565162951538e-05, 'epoch': 1.6514806378132119, 'num_input_tokens_seen': 1247404}\n",
      "{'loss': 0.3568, 'grad_norm': 4.4051313400268555, 'learning_rate': 1.9396926207859085e-05, 'epoch': 1.7084282460136673, 'num_input_tokens_seen': 1293004}\n",
      "{'loss': 0.3399, 'grad_norm': 12.274831771850586, 'learning_rate': 1.9271838545667876e-05, 'epoch': 1.7653758542141231, 'num_input_tokens_seen': 1337132}\n",
      "{'loss': 0.3328, 'grad_norm': 5.851895809173584, 'learning_rate': 1.913545457642601e-05, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1379180}\n",
      "{'eval_loss': 0.3637441396713257, 'eval_overall_precision': 0.35355777531138244, 'eval_overall_recall': 0.4819297360900992, 'eval_overall_f1': 0.40788163323374593, 'eval_PER_precision': 0.36034540019926936, 'eval_PER_recall': 0.5890336590662324, 'eval_PER_f1': 0.44714609519884607, 'eval_LOC_precision': 0.5395220588235294, 'eval_LOC_recall': 0.6390854654327708, 'eval_LOC_f1': 0.585098430102168, 'eval_ORG_precision': 0.296730112249878, 'eval_ORG_recall': 0.4523809523809524, 'eval_ORG_f1': 0.35838491010904805, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 8.9976, 'eval_samples_per_second': 361.206, 'eval_steps_per_second': 2.89, 'epoch': 1.8223234624145785, 'num_input_tokens_seen': 1379180}\n",
      "{'loss': 0.3068, 'grad_norm': 11.012502670288086, 'learning_rate': 1.8987940462991673e-05, 'epoch': 1.8792710706150342, 'num_input_tokens_seen': 1420044}\n",
      "{'loss': 0.3169, 'grad_norm': 6.237310886383057, 'learning_rate': 1.8829475928589272e-05, 'epoch': 1.9362186788154898, 'num_input_tokens_seen': 1460844}\n",
      "{'loss': 0.2757, 'grad_norm': 10.110700607299805, 'learning_rate': 1.866025403784439e-05, 'epoch': 1.9931662870159452, 'num_input_tokens_seen': 1506860}\n",
      "{'loss': 0.2877, 'grad_norm': 7.354301929473877, 'learning_rate': 1.848048096156426e-05, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1549005}\n",
      "{'eval_loss': 0.3409242033958435, 'eval_overall_precision': 0.35256793966239675, 'eval_overall_recall': 0.49504118339216674, 'eval_overall_f1': 0.41183051321493497, 'eval_PER_precision': 0.34981623788840627, 'eval_PER_recall': 0.5684039087947883, 'eval_PER_f1': 0.4330920372285419, 'eval_LOC_precision': 0.5616315553563425, 'eval_LOC_recall': 0.6820903647250952, 'eval_LOC_f1': 0.6160275319567355, 'eval_ORG_precision': 0.2870493991989319, 'eval_ORG_recall': 0.4799107142857143, 'eval_ORG_f1': 0.35923141186299085, 'eval_MISC_precision': 0.0, 'eval_MISC_recall': 0.0, 'eval_MISC_f1': 0, 'eval_runtime': 9.2631, 'eval_samples_per_second': 350.856, 'eval_steps_per_second': 2.807, 'epoch': 2.050113895216401, 'num_input_tokens_seen': 1549005}\n",
      "{'loss': 0.2643, 'grad_norm': 8.154258728027344, 'learning_rate': 1.8290375725550417e-05, 'epoch': 2.1070615034168565, 'num_input_tokens_seen': 1592877}\n",
      "{'loss': 0.2757, 'grad_norm': 7.863979339599609, 'learning_rate': 1.8090169943749477e-05, 'epoch': 2.164009111617312, 'num_input_tokens_seen': 1633837}\n",
      "{'loss': 0.272, 'grad_norm': 8.953521728515625, 'learning_rate': 1.788010753606722e-05, 'epoch': 2.2209567198177678, 'num_input_tokens_seen': 1678669}\n",
      "{'loss': 0.2603, 'grad_norm': 5.831000804901123, 'learning_rate': 1.766044443118978e-05, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1722573}\n",
      "{'eval_loss': 0.34395191073417664, 'eval_overall_precision': 0.36429193087156536, 'eval_overall_recall': 0.49251975121869224, 'eval_overall_f1': 0.4188107489994283, 'eval_PER_precision': 0.333454018826937, 'eval_PER_recall': 0.5, 'eval_PER_f1': 0.4000868809730669, 'eval_LOC_precision': 0.5899912203687445, 'eval_LOC_recall': 0.7316276537833424, 'eval_LOC_f1': 0.6532199270959903, 'eval_ORG_precision': 0.3102310231023102, 'eval_ORG_recall': 0.4895833333333333, 'eval_ORG_f1': 0.3797979797979798, 'eval_MISC_precision': 0.007936507936507936, 'eval_MISC_recall': 0.00755939524838013, 'eval_MISC_f1': 0.007743362831858408, 'eval_runtime': 8.6985, 'eval_samples_per_second': 373.627, 'eval_steps_per_second': 2.989, 'epoch': 2.277904328018223, 'num_input_tokens_seen': 1722573}\n",
      "{'loss': 0.2454, 'grad_norm': 7.681509971618652, 'learning_rate': 1.7431448254773943e-05, 'epoch': 2.334851936218679, 'num_input_tokens_seen': 1765069}\n",
      "{'loss': 0.2501, 'grad_norm': 5.741202354431152, 'learning_rate': 1.7193398003386514e-05, 'epoch': 2.3917995444191344, 'num_input_tokens_seen': 1807981}\n",
      "{'loss': 0.2401, 'grad_norm': 14.678631782531738, 'learning_rate': 1.6946583704589973e-05, 'epoch': 2.44874715261959, 'num_input_tokens_seen': 1851149}\n",
      "{'loss': 0.2506, 'grad_norm': 11.881019592285156, 'learning_rate': 1.6691306063588583e-05, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1891373}\n",
      "{'eval_loss': 0.3425788879394531, 'eval_overall_precision': 0.35215210544733466, 'eval_overall_recall': 0.5074802487813078, 'eval_overall_f1': 0.4157829500068861, 'eval_PER_precision': 0.29419657832941964, 'eval_PER_recall': 0.4761129207383279, 'eval_PER_f1': 0.36367406178726935, 'eval_LOC_precision': 0.5761400651465798, 'eval_LOC_recall': 0.7702776265650517, 'eval_LOC_f1': 0.6592126717912881, 'eval_ORG_precision': 0.2999540652273771, 'eval_ORG_recall': 0.48586309523809523, 'eval_ORG_f1': 0.37091735302470885, 'eval_MISC_precision': 0.07716371220020855, 'eval_MISC_recall': 0.07991360691144708, 'eval_MISC_f1': 0.07851458885941646, 'eval_runtime': 9.3178, 'eval_samples_per_second': 348.793, 'eval_steps_per_second': 2.79, 'epoch': 2.5056947608200457, 'num_input_tokens_seen': 1891373}\n",
      "{'loss': 0.214, 'grad_norm': 15.166918754577637, 'learning_rate': 1.6427876096865394e-05, 'epoch': 2.562642369020501, 'num_input_tokens_seen': 1935405}\n",
      "{'loss': 0.2262, 'grad_norm': 14.501440048217773, 'learning_rate': 1.6156614753256583e-05, 'epoch': 2.619589977220957, 'num_input_tokens_seen': 1978701}\n",
      "{'loss': 0.2277, 'grad_norm': 10.914456367492676, 'learning_rate': 1.5877852522924733e-05, 'epoch': 2.6765375854214124, 'num_input_tokens_seen': 2020653}\n",
      "{'loss': 0.219, 'grad_norm': 13.693299293518066, 'learning_rate': 1.5591929034707468e-05, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 2062477}\n",
      "{'eval_loss': 0.3255774974822998, 'eval_overall_precision': 0.38762173244490006, 'eval_overall_recall': 0.5084888216506976, 'eval_overall_f1': 0.43990402094088565, 'eval_PER_precision': 0.33664383561643835, 'eval_PER_recall': 0.5336590662323561, 'eval_PER_f1': 0.4128517429651407, 'eval_LOC_precision': 0.5839144583914458, 'eval_LOC_recall': 0.683723462166576, 'eval_LOC_f1': 0.629889669007021, 'eval_ORG_precision': 0.3497237569060773, 'eval_ORG_recall': 0.47098214285714285, 'eval_ORG_f1': 0.40139505389980973, 'eval_MISC_precision': 0.1657638136511376, 'eval_MISC_recall': 0.1652267818574514, 'eval_MISC_f1': 0.16549486208761494, 'eval_runtime': 8.5446, 'eval_samples_per_second': 380.355, 'eval_steps_per_second': 3.043, 'epoch': 2.733485193621868, 'num_input_tokens_seen': 2062477}\n",
      "{'loss': 0.2143, 'grad_norm': 6.951714515686035, 'learning_rate': 1.529919264233205e-05, 'epoch': 2.7904328018223232, 'num_input_tokens_seen': 2108109}\n",
      "{'loss': 0.2294, 'grad_norm': 8.04030990600586, 'learning_rate': 1.5000000000000002e-05, 'epoch': 2.847380410022779, 'num_input_tokens_seen': 2154861}\n",
      "{'loss': 0.2078, 'grad_norm': 15.433305740356445, 'learning_rate': 1.469471562785891e-05, 'epoch': 2.9043280182232345, 'num_input_tokens_seen': 2200397}\n",
      "{'loss': 0.2112, 'grad_norm': 7.568130970001221, 'learning_rate': 1.4383711467890776e-05, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2242701}\n",
      "{'eval_loss': 0.2982681691646576, 'eval_overall_precision': 0.39711465451784356, 'eval_overall_recall': 0.5274836106908725, 'eval_overall_f1': 0.453108078839073, 'eval_PER_precision': 0.31580792148615494, 'eval_PER_recall': 0.48914223669923995, 'eval_PER_f1': 0.3838125665601704, 'eval_LOC_precision': 0.590867992766727, 'eval_LOC_recall': 0.7114861186717474, 'eval_LOC_f1': 0.6455915040750804, 'eval_ORG_precision': 0.3545258620689655, 'eval_ORG_recall': 0.4895833333333333, 'eval_ORG_f1': 0.41125000000000006, 'eval_MISC_precision': 0.27726809378185524, 'eval_MISC_recall': 0.2937365010799136, 'eval_MISC_f1': 0.28526481384373364, 'eval_runtime': 8.4765, 'eval_samples_per_second': 383.412, 'eval_steps_per_second': 3.067, 'epoch': 2.9612756264236904, 'num_input_tokens_seen': 2242701}\n",
      "{'loss': 0.2081, 'grad_norm': 5.239500999450684, 'learning_rate': 1.4067366430758004e-05, 'epoch': 3.0182232346241458, 'num_input_tokens_seen': 2283551}\n",
      "{'loss': 0.2022, 'grad_norm': 14.157790184020996, 'learning_rate': 1.3746065934159123e-05, 'epoch': 3.075170842824601, 'num_input_tokens_seen': 2327007}\n",
      "{'loss': 0.1861, 'grad_norm': 12.39835262298584, 'learning_rate': 1.342020143325669e-05, 'epoch': 3.132118451025057, 'num_input_tokens_seen': 2370143}\n",
      "{'loss': 0.1848, 'grad_norm': 14.430689811706543, 'learning_rate': 1.3090169943749475e-05, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2412319}\n",
      "{'eval_loss': 0.3314908444881439, 'eval_overall_precision': 0.3823152995927865, 'eval_overall_recall': 0.5523617414691545, 'eval_overall_f1': 0.45187018701870185, 'eval_PER_precision': 0.3486864551347663, 'eval_PER_recall': 0.5548317046688382, 'eval_PER_f1': 0.42824219568405614, 'eval_LOC_precision': 0.5523450586264657, 'eval_LOC_recall': 0.7180185084376701, 'eval_LOC_f1': 0.6243786982248521, 'eval_ORG_precision': 0.30840258541089566, 'eval_ORG_recall': 0.49702380952380953, 'eval_ORG_f1': 0.3806267806267807, 'eval_MISC_precision': 0.24954954954954955, 'eval_MISC_recall': 0.2991360691144708, 'eval_MISC_f1': 0.27210216110019647, 'eval_runtime': 9.1619, 'eval_samples_per_second': 354.728, 'eval_steps_per_second': 2.838, 'epoch': 3.1890660592255125, 'num_input_tokens_seen': 2412319}\n",
      "{'loss': 0.1928, 'grad_norm': 18.090585708618164, 'learning_rate': 1.2756373558169992e-05, 'epoch': 3.2460136674259683, 'num_input_tokens_seen': 2453279}\n",
      "{'loss': 0.1886, 'grad_norm': 16.917583465576172, 'learning_rate': 1.2419218955996677e-05, 'epoch': 3.3029612756264237, 'num_input_tokens_seen': 2496511}\n",
      "{'loss': 0.1873, 'grad_norm': 20.951650619506836, 'learning_rate': 1.2079116908177592e-05, 'epoch': 3.359908883826879, 'num_input_tokens_seen': 2540191}\n",
      "{'loss': 0.1839, 'grad_norm': 9.611383438110352, 'learning_rate': 1.1736481776669307e-05, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2584319}\n",
      "{'eval_loss': 0.35162612795829773, 'eval_overall_precision': 0.36512721572410467, 'eval_overall_recall': 0.5089931080853926, 'eval_overall_f1': 0.4252211768010111, 'eval_PER_precision': 0.2639821029082774, 'eval_PER_recall': 0.38436482084690554, 'eval_PER_f1': 0.3129973474801061, 'eval_LOC_precision': 0.5647058823529412, 'eval_LOC_recall': 0.6793685356559608, 'eval_LOC_f1': 0.6167531504818383, 'eval_ORG_precision': 0.31338786052518297, 'eval_ORG_recall': 0.5416666666666666, 'eval_ORG_f1': 0.3970548131988001, 'eval_MISC_precision': 0.31910946196660483, 'eval_MISC_recall': 0.3714902807775378, 'eval_MISC_f1': 0.34331337325349304, 'eval_runtime': 9.0588, 'eval_samples_per_second': 358.768, 'eval_steps_per_second': 2.87, 'epoch': 3.416856492027335, 'num_input_tokens_seen': 2584319}\n",
      "{'loss': 0.179, 'grad_norm': 8.531463623046875, 'learning_rate': 1.1391731009600655e-05, 'epoch': 3.4738041002277904, 'num_input_tokens_seen': 2626079}\n",
      "{'loss': 0.172, 'grad_norm': 8.348077774047852, 'learning_rate': 1.1045284632676535e-05, 'epoch': 3.5307517084282463, 'num_input_tokens_seen': 2672351}\n",
      "{'loss': 0.1671, 'grad_norm': 15.305667877197266, 'learning_rate': 1.0697564737441254e-05, 'epoch': 3.5876993166287017, 'num_input_tokens_seen': 2715167}\n",
      "{'loss': 0.1729, 'grad_norm': 13.005736351013184, 'learning_rate': 1.0348994967025012e-05, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2762047}\n",
      "{'eval_loss': 0.3152290880680084, 'eval_overall_precision': 0.421220633299285, 'eval_overall_recall': 0.5545469826861658, 'eval_overall_f1': 0.4787751251723388, 'eval_PER_precision': 0.3467834031214313, 'eval_PER_recall': 0.49457111834962, 'eval_PER_f1': 0.4076974714701276, 'eval_LOC_precision': 0.6013729977116705, 'eval_LOC_recall': 0.7152966793685357, 'eval_LOC_f1': 0.6534062655395326, 'eval_ORG_precision': 0.35931174089068824, 'eval_ORG_recall': 0.5282738095238095, 'eval_ORG_f1': 0.4277108433734939, 'eval_MISC_precision': 0.3486590038314176, 'eval_MISC_recall': 0.3930885529157667, 'eval_MISC_f1': 0.36954314720812187, 'eval_runtime': 8.578, 'eval_samples_per_second': 378.878, 'eval_steps_per_second': 3.031, 'epoch': 3.644646924829157, 'num_input_tokens_seen': 2762047}\n",
      "{'loss': 0.1736, 'grad_norm': 5.769322872161865, 'learning_rate': 1e-05, 'epoch': 3.7015945330296125, 'num_input_tokens_seen': 2801695}\n",
      "{'loss': 0.1801, 'grad_norm': 14.880609512329102, 'learning_rate': 9.651005032974994e-06, 'epoch': 3.7585421412300684, 'num_input_tokens_seen': 2846815}\n",
      "{'loss': 0.1686, 'grad_norm': 8.566727638244629, 'learning_rate': 9.302435262558748e-06, 'epoch': 3.8154897494305238, 'num_input_tokens_seen': 2888031}\n",
      "{'loss': 0.1588, 'grad_norm': 7.018430709838867, 'learning_rate': 8.954715367323468e-06, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2929855}\n",
      "{'eval_loss': 0.2995373606681824, 'eval_overall_precision': 0.4380422115758125, 'eval_overall_recall': 0.5686670028576232, 'eval_overall_f1': 0.49488004681100056, 'eval_PER_precision': 0.38905891354246364, 'eval_PER_recall': 0.5521172638436482, 'eval_PER_f1': 0.4564631956912029, 'eval_LOC_precision': 0.5852749301025163, 'eval_LOC_recall': 0.683723462166576, 'eval_LOC_f1': 0.6306803916645745, 'eval_ORG_precision': 0.3746729461015175, 'eval_ORG_recall': 0.5327380952380952, 'eval_ORG_f1': 0.4399385560675883, 'eval_MISC_precision': 0.3745247148288973, 'eval_MISC_recall': 0.42548596112311016, 'eval_MISC_f1': 0.39838220424671383, 'eval_runtime': 7.826, 'eval_samples_per_second': 415.282, 'eval_steps_per_second': 3.322, 'epoch': 3.8724373576309796, 'num_input_tokens_seen': 2929855}\n",
      "{'loss': 0.1736, 'grad_norm': 8.712981224060059, 'learning_rate': 8.60826899039935e-06, 'epoch': 3.929384965831435, 'num_input_tokens_seen': 2974271}\n",
      "{'loss': 0.1482, 'grad_norm': 20.589122772216797, 'learning_rate': 8.263518223330698e-06, 'epoch': 3.9863325740318905, 'num_input_tokens_seen': 3016511}\n",
      "{'loss': 0.1553, 'grad_norm': 21.01667594909668, 'learning_rate': 7.92088309182241e-06, 'epoch': 4.043280182232346, 'num_input_tokens_seen': 3060327}\n",
      "{'loss': 0.1567, 'grad_norm': 43.135231018066406, 'learning_rate': 7.580781044003324e-06, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 3103751}\n",
      "{'eval_loss': 0.29639381170272827, 'eval_overall_precision': 0.4381894256371244, 'eval_overall_recall': 0.5809379727685325, 'eval_overall_f1': 0.4995663486556808, 'eval_PER_precision': 0.36722960833632773, 'eval_PER_recall': 0.5548317046688382, 'eval_PER_f1': 0.44194594594594594, 'eval_LOC_precision': 0.618732261116367, 'eval_LOC_recall': 0.7120304844855743, 'eval_LOC_f1': 0.6621108580106302, 'eval_ORG_precision': 0.3793284365162644, 'eval_ORG_recall': 0.5379464285714286, 'eval_ORG_f1': 0.444923076923077, 'eval_MISC_precision': 0.37177121771217714, 'eval_MISC_recall': 0.4352051835853132, 'eval_MISC_f1': 0.4009950248756219, 'eval_runtime': 8.079, 'eval_samples_per_second': 402.278, 'eval_steps_per_second': 3.218, 'epoch': 4.100227790432802, 'num_input_tokens_seen': 3103751}\n",
      "{'loss': 0.1619, 'grad_norm': 10.961114883422852, 'learning_rate': 7.243626441830009e-06, 'epoch': 4.157175398633258, 'num_input_tokens_seen': 3145287}\n",
      "{'loss': 0.1591, 'grad_norm': 13.179808616638184, 'learning_rate': 6.909830056250527e-06, 'epoch': 4.214123006833713, 'num_input_tokens_seen': 3188263}\n",
      "{'loss': 0.1501, 'grad_norm': 18.755760192871094, 'learning_rate': 6.579798566743314e-06, 'epoch': 4.271070615034168, 'num_input_tokens_seen': 3232487}\n",
      "{'loss': 0.1541, 'grad_norm': 14.778594970703125, 'learning_rate': 6.25393406584088e-06, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 3279175}\n",
      "{'eval_loss': 0.2985454201698303, 'eval_overall_precision': 0.43646751956278723, 'eval_overall_recall': 0.5906875105059674, 'eval_overall_f1': 0.502, 'eval_PER_precision': 0.3798219584569733, 'eval_PER_recall': 0.5559174809989142, 'eval_PER_f1': 0.4513001322168356, 'eval_LOC_precision': 0.6007146047342564, 'eval_LOC_recall': 0.7321720195971693, 'eval_LOC_f1': 0.6599607458292444, 'eval_ORG_precision': 0.37195767195767193, 'eval_ORG_recall': 0.5230654761904762, 'eval_ORG_f1': 0.43475572047000616, 'eval_MISC_precision': 0.3605220228384992, 'eval_MISC_recall': 0.4773218142548596, 'eval_MISC_f1': 0.41078066914498146, 'eval_runtime': 8.2801, 'eval_samples_per_second': 392.507, 'eval_steps_per_second': 3.14, 'epoch': 4.328018223234624, 'num_input_tokens_seen': 3279175}\n",
      "{'loss': 0.1502, 'grad_norm': 57.923954010009766, 'learning_rate': 5.932633569242e-06, 'epoch': 4.38496583143508, 'num_input_tokens_seen': 3321287}\n",
      "{'loss': 0.1468, 'grad_norm': 4.075605869293213, 'learning_rate': 5.616288532109225e-06, 'epoch': 4.4419134396355355, 'num_input_tokens_seen': 3363623}\n",
      "{'loss': 0.1421, 'grad_norm': 18.38970184326172, 'learning_rate': 5.305284372141095e-06, 'epoch': 4.498861047835991, 'num_input_tokens_seen': 3406599}\n",
      "{'loss': 0.1501, 'grad_norm': 21.652542114257812, 'learning_rate': 5.000000000000003e-06, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3449095}\n",
      "{'eval_loss': 0.29383641481399536, 'eval_overall_precision': 0.44610552763819095, 'eval_overall_recall': 0.5969070432005379, 'eval_overall_f1': 0.5106046444748005, 'eval_PER_precision': 0.4009807619766126, 'eval_PER_recall': 0.5770901194353963, 'eval_PER_f1': 0.47318050300467396, 'eval_LOC_precision': 0.6024646280237335, 'eval_LOC_recall': 0.718562874251497, 'eval_LOC_f1': 0.6554121151936445, 'eval_ORG_precision': 0.3723785166240409, 'eval_ORG_recall': 0.5416666666666666, 'eval_ORG_f1': 0.4413458623825402, 'eval_MISC_precision': 0.37833190025795355, 'eval_MISC_recall': 0.47516198704103674, 'eval_MISC_f1': 0.42125418860698893, 'eval_runtime': 8.3002, 'eval_samples_per_second': 391.558, 'eval_steps_per_second': 3.132, 'epoch': 4.555808656036446, 'num_input_tokens_seen': 3449095}\n",
      "{'loss': 0.1561, 'grad_norm': 7.558985233306885, 'learning_rate': 4.700807357667953e-06, 'epoch': 4.612756264236902, 'num_input_tokens_seen': 3491591}\n",
      "{'loss': 0.1485, 'grad_norm': 4.39093542098999, 'learning_rate': 4.408070965292534e-06, 'epoch': 4.669703872437358, 'num_input_tokens_seen': 3533639}\n",
      "{'loss': 0.1389, 'grad_norm': 14.83499526977539, 'learning_rate': 4.12214747707527e-06, 'epoch': 4.7266514806378135, 'num_input_tokens_seen': 3576231}\n",
      "{'loss': 0.15, 'grad_norm': 20.274707794189453, 'learning_rate': 3.8433852467434175e-06, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3619495}\n",
      "{'eval_loss': 0.3046819865703583, 'eval_overall_precision': 0.4603234773818549, 'eval_overall_recall': 0.6123718271978483, 'eval_overall_f1': 0.5255716655846497, 'eval_PER_precision': 0.42592592592592593, 'eval_PER_recall': 0.6118349619978285, 'eval_PER_f1': 0.5022281639928698, 'eval_LOC_precision': 0.5943127962085308, 'eval_LOC_recall': 0.6826347305389222, 'eval_LOC_f1': 0.6354193058018749, 'eval_ORG_precision': 0.3916540975364505, 'eval_ORG_recall': 0.5796130952380952, 'eval_ORG_f1': 0.46744674467446745, 'eval_MISC_precision': 0.41317365269461076, 'eval_MISC_recall': 0.521598272138229, 'eval_MISC_f1': 0.4610978520286396, 'eval_runtime': 7.8656, 'eval_samples_per_second': 413.191, 'eval_steps_per_second': 3.306, 'epoch': 4.783599088838269, 'num_input_tokens_seen': 3619495}\n",
      "{'loss': 0.1522, 'grad_norm': 11.010998725891113, 'learning_rate': 3.5721239031346067e-06, 'epoch': 4.840546697038724, 'num_input_tokens_seen': 3662919}\n",
      "{'loss': 0.1496, 'grad_norm': 4.4469733238220215, 'learning_rate': 3.308693936411421e-06, 'epoch': 4.89749430523918, 'num_input_tokens_seen': 3705831}\n",
      "{'loss': 0.1411, 'grad_norm': 8.224136352539062, 'learning_rate': 3.0534162954100264e-06, 'epoch': 4.954441913439636, 'num_input_tokens_seen': 3749255}\n",
      "{'loss': 0.1334, 'grad_norm': 14.949734687805176, 'learning_rate': 2.8066019966134907e-06, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3794120}\n",
      "{'eval_loss': 0.3012743890285492, 'eval_overall_precision': 0.46825294193715244, 'eval_overall_recall': 0.6086737266767523, 'eval_overall_f1': 0.5293085806168689, 'eval_PER_precision': 0.4426656738644825, 'eval_PER_recall': 0.6454940282301845, 'eval_PER_f1': 0.5251766784452297, 'eval_LOC_precision': 0.6140939597315436, 'eval_LOC_recall': 0.6973326075122482, 'eval_LOC_f1': 0.6530716288554677, 'eval_ORG_precision': 0.3575240128068303, 'eval_ORG_recall': 0.49851190476190477, 'eval_ORG_f1': 0.41640770665009325, 'eval_MISC_precision': 0.44250229990800366, 'eval_MISC_recall': 0.519438444924406, 'eval_MISC_f1': 0.47789369100844503, 'eval_runtime': 7.7819, 'eval_samples_per_second': 417.637, 'eval_steps_per_second': 3.341, 'epoch': 5.011389521640091, 'num_input_tokens_seen': 3794120}\n",
      "{'loss': 0.1433, 'grad_norm': 22.2261962890625, 'learning_rate': 2.5685517452260566e-06, 'epoch': 5.068337129840547, 'num_input_tokens_seen': 3837160}\n",
      "{'loss': 0.1402, 'grad_norm': 5.713444709777832, 'learning_rate': 2.339555568810221e-06, 'epoch': 5.125284738041002, 'num_input_tokens_seen': 3881992}\n",
      "{'loss': 0.1321, 'grad_norm': 18.430706024169922, 'learning_rate': 2.119892463932781e-06, 'epoch': 5.182232346241458, 'num_input_tokens_seen': 3924328}\n",
      "{'loss': 0.1265, 'grad_norm': 14.002846717834473, 'learning_rate': 1.9098300562505266e-06, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3965704}\n",
      "{'eval_loss': 0.305623859167099, 'eval_overall_precision': 0.4670666492761184, 'eval_overall_recall': 0.601949907547487, 'eval_overall_f1': 0.5259988249118683, 'eval_PER_precision': 0.44072363356428024, 'eval_PER_recall': 0.6216069489685125, 'eval_PER_f1': 0.5157657657657657, 'eval_LOC_precision': 0.6000964785335263, 'eval_LOC_recall': 0.6771910724006532, 'eval_LOC_f1': 0.6363171355498722, 'eval_ORG_precision': 0.3801478352692714, 'eval_ORG_recall': 0.5357142857142857, 'eval_ORG_f1': 0.4447189623224212, 'eval_MISC_precision': 0.4283121597096189, 'eval_MISC_recall': 0.509719222462203, 'eval_MISC_f1': 0.46548323471400394, 'eval_runtime': 7.6776, 'eval_samples_per_second': 423.308, 'eval_steps_per_second': 3.386, 'epoch': 5.239179954441913, 'num_input_tokens_seen': 3965704}\n",
      "{'loss': 0.129, 'grad_norm': 6.66945219039917, 'learning_rate': 1.709624274449584e-06, 'epoch': 5.296127562642369, 'num_input_tokens_seen': 4009800}\n",
      "{'loss': 0.1459, 'grad_norm': 23.310970306396484, 'learning_rate': 1.5195190384357405e-06, 'epoch': 5.353075170842825, 'num_input_tokens_seen': 4052968}\n",
      "{'loss': 0.1176, 'grad_norm': 11.308915138244629, 'learning_rate': 1.339745962155613e-06, 'epoch': 5.41002277904328, 'num_input_tokens_seen': 4096136}\n",
      "{'loss': 0.1307, 'grad_norm': 10.857857704162598, 'learning_rate': 1.1705240714107301e-06, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 4138312}\n",
      "{'eval_loss': 0.30492156744003296, 'eval_overall_precision': 0.45652173913043476, 'eval_overall_recall': 0.6036308623298033, 'eval_overall_f1': 0.5198697068403909, 'eval_PER_precision': 0.42077331311599697, 'eval_PER_recall': 0.6026058631921825, 'eval_PER_f1': 0.4955357142857143, 'eval_LOC_precision': 0.6214185063410052, 'eval_LOC_recall': 0.7201959716929777, 'eval_LOC_f1': 0.6671709531013615, 'eval_ORG_precision': 0.3630831643002028, 'eval_ORG_recall': 0.5327380952380952, 'eval_ORG_f1': 0.43184559710494574, 'eval_MISC_precision': 0.3921916592724046, 'eval_MISC_recall': 0.4773218142548596, 'eval_MISC_f1': 0.4305893813930833, 'eval_runtime': 7.9906, 'eval_samples_per_second': 406.727, 'eval_steps_per_second': 3.254, 'epoch': 5.466970387243736, 'num_input_tokens_seen': 4138312}\n",
      "{'loss': 0.1377, 'grad_norm': 18.378015518188477, 'learning_rate': 1.012059537008332e-06, 'epoch': 5.523917995444191, 'num_input_tokens_seen': 4177704}\n",
      "{'loss': 0.146, 'grad_norm': 15.757765769958496, 'learning_rate': 8.645454235739903e-07, 'epoch': 5.5808656036446465, 'num_input_tokens_seen': 4221256}\n",
      "{'loss': 0.1313, 'grad_norm': 14.79470157623291, 'learning_rate': 7.281614543321269e-07, 'epoch': 5.637813211845103, 'num_input_tokens_seen': 4264456}\n",
      "{'loss': 0.1248, 'grad_norm': 8.122414588928223, 'learning_rate': 6.030737921409169e-07, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 4311272}\n",
      "{'eval_loss': 0.29696664214134216, 'eval_overall_precision': 0.4643903681997707, 'eval_overall_recall': 0.6127080181543116, 'eval_overall_f1': 0.5283374402087259, 'eval_PER_precision': 0.42260536398467435, 'eval_PER_recall': 0.5988056460369164, 'eval_PER_f1': 0.495507637017071, 'eval_LOC_precision': 0.6217978574755473, 'eval_LOC_recall': 0.7267283614589004, 'eval_LOC_f1': 0.6701807228915663, 'eval_ORG_precision': 0.3782249742002064, 'eval_ORG_recall': 0.5453869047619048, 'eval_ORG_f1': 0.4466788543570993, 'eval_MISC_precision': 0.41074523396880414, 'eval_MISC_recall': 0.5118790496760259, 'eval_MISC_f1': 0.4557692307692308, 'eval_runtime': 7.8923, 'eval_samples_per_second': 411.792, 'eval_steps_per_second': 3.294, 'epoch': 5.694760820045558, 'num_input_tokens_seen': 4311272}\n",
      "{'loss': 0.133, 'grad_norm': 12.684972763061523, 'learning_rate': 4.894348370484648e-07, 'epoch': 5.751708428246014, 'num_input_tokens_seen': 4353224}\n",
      "{'loss': 0.1386, 'grad_norm': 6.701418399810791, 'learning_rate': 3.8738304061681107e-07, 'epoch': 5.808656036446469, 'num_input_tokens_seen': 4397832}\n",
      "{'loss': 0.1396, 'grad_norm': 25.750686645507812, 'learning_rate': 2.970427372400353e-07, 'epoch': 5.865603644646924, 'num_input_tokens_seen': 4442504}\n",
      "{'loss': 0.1346, 'grad_norm': 12.68244457244873, 'learning_rate': 2.1852399266194312e-07, 'epoch': 5.922551252847381, 'num_input_tokens_seen': 4485352}\n",
      "{'eval_loss': 0.305143803358078, 'eval_overall_precision': 0.4572617246596067, 'eval_overall_recall': 0.6096822995461422, 'eval_overall_f1': 0.5225848281824076, 'eval_PER_precision': 0.4239212717638153, 'eval_PER_recall': 0.6080347448425625, 'eval_PER_f1': 0.49955396966993765, 'eval_LOC_precision': 0.6180717279925477, 'eval_LOC_recall': 0.7223734349482852, 'eval_LOC_f1': 0.6661646586345381, 'eval_ORG_precision': 0.36340598073998986, 'eval_ORG_recall': 0.5334821428571429, 'eval_ORG_f1': 0.4323183599638228, 'eval_MISC_precision': 0.3957264957264957, 'eval_MISC_recall': 0.5, 'eval_MISC_f1': 0.441793893129771, 'eval_runtime': 7.737, 'eval_samples_per_second': 420.061, 'eval_steps_per_second': 3.36, 'epoch': 5.922551252847381, 'num_input_tokens_seen': 4485352}\n",
      "{'loss': 0.1266, 'grad_norm': 15.147852897644043, 'learning_rate': 1.519224698779198e-07, 'epoch': 5.979498861047836, 'num_input_tokens_seen': 4531272}\n",
      "{'loss': 0.1422, 'grad_norm': 11.446057319641113, 'learning_rate': 9.731931258429638e-08, 'epoch': 6.0364464692482915, 'num_input_tokens_seen': 4574753}\n",
      "{'loss': 0.1224, 'grad_norm': 17.9492130279541, 'learning_rate': 5.4781046317267103e-08, 'epoch': 6.093394077448747, 'num_input_tokens_seen': 4620257}\n",
      "{'loss': 0.1246, 'grad_norm': 23.896059036254883, 'learning_rate': 2.4359497401758026e-08, 'epoch': 6.150341685649202, 'num_input_tokens_seen': 4663233}\n",
      "{'eval_loss': 0.3044007420539856, 'eval_overall_precision': 0.4555751321419582, 'eval_overall_recall': 0.6085056311985207, 'eval_overall_f1': 0.5210507376754228, 'eval_PER_precision': 0.41694915254237286, 'eval_PER_recall': 0.6009771986970684, 'eval_PER_f1': 0.4923282188125417, 'eval_LOC_precision': 0.6197380729653882, 'eval_LOC_recall': 0.7212847033206314, 'eval_LOC_f1': 0.6666666666666666, 'eval_ORG_precision': 0.36446239273094394, 'eval_ORG_recall': 0.5372023809523809, 'eval_ORG_f1': 0.4342857142857142, 'eval_MISC_precision': 0.39761092150170646, 'eval_MISC_recall': 0.5032397408207343, 'eval_MISC_f1': 0.44423260247855095, 'eval_runtime': 8.0931, 'eval_samples_per_second': 401.575, 'eval_steps_per_second': 3.213, 'epoch': 6.150341685649202, 'num_input_tokens_seen': 4663233}\n",
      "{'loss': 0.1259, 'grad_norm': 29.285884857177734, 'learning_rate': 6.091729809042379e-09, 'epoch': 6.207289293849659, 'num_input_tokens_seen': 4705825}\n",
      "{'loss': 0.1265, 'grad_norm': 6.703178882598877, 'learning_rate': 0.0, 'epoch': 6.264236902050114, 'num_input_tokens_seen': 4749665}\n",
      "{'loss': 0.1203, 'grad_norm': 11.723187446594238, 'learning_rate': 6.091729809042379e-09, 'epoch': 6.3211845102505695, 'num_input_tokens_seen': 4792257}\n",
      "{'loss': 0.135, 'grad_norm': 18.692047119140625, 'learning_rate': 2.4359497401756915e-08, 'epoch': 6.378132118451025, 'num_input_tokens_seen': 4834785}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 30\u001B[0m\n\u001B[1;32m      2\u001B[0m xlm_tok \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfacebook/xlm-v-base\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      5\u001B[0m     args\u001B[38;5;241m=\u001B[39mTrainingArguments(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_ner_metrics\n\u001B[1;32m     29\u001B[0m )\n\u001B[0;32m---> 30\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:1938\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1936\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1939\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1943\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:2356\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2353\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[1;32m   2354\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m-> 2356\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2357\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2358\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:2804\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2802\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_evaluate:\n\u001B[0;32m-> 2804\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[1;32m   2807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_checkpoint(model, trial, metrics\u001B[38;5;241m=\u001B[39mmetrics)\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:2761\u001B[0m, in \u001B[0;36mTrainer._evaluate\u001B[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[0m\n\u001B[1;32m   2760\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m-> 2761\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2762\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[1;32m   2764\u001B[0m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:3666\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3663\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3665\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3666\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3667\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3669\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   3670\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   3671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3672\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3674\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3676\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3677\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:3956\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3952\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[1;32m   3953\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[1;32m   3954\u001B[0m         )\n\u001B[1;32m   3955\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3956\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3957\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3958\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[0;32mIn[19], line 14\u001B[0m, in \u001B[0;36mcompute_ner_metrics\u001B[0;34m(eval_pred)\u001B[0m\n\u001B[1;32m     11\u001B[0m labels \u001B[38;5;241m=\u001B[39m ner_tags_scheme[labels]\n\u001B[1;32m     13\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m nervaluate\u001B[38;5;241m.\u001B[39mEvaluator([labels], [predictions], tags\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPER\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLOC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mORG\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMISC\u001B[39m\u001B[38;5;124m'\u001B[39m], loader\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlist\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m results, results_per_tag, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m overall_metrics \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     18\u001B[0m metrics \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverall_precision\u001B[39m\u001B[38;5;124m'\u001B[39m: overall_metrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverall_recall\u001B[39m\u001B[38;5;124m'\u001B[39m: overall_metrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverall_f1\u001B[39m\u001B[38;5;124m'\u001B[39m: overall_metrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     22\u001B[0m }\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/nervaluate/evaluate.py:84\u001B[0m, in \u001B[0;36mEvaluator.evaluate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of predicted documents does not equal true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, (true_ents, pred_ents) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrue, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpred)):\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;66;03m# Compute results for one message\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m     tmp_results, tmp_agg_results, tmp_results_indices, tmp_agg_results_indices \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_ents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_ents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;66;03m# Cycle through each result and accumulate\u001B[39;00m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;66;03m# TODO: Combine these loops below:\u001B[39;00m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m eval_schema \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults:\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/nervaluate/evaluate.py:248\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[0;34m(true_named_entities, pred_named_entities, tags, instance_index)\u001B[0m\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;66;03m# overlapping needs to take into account last token as well\u001B[39;00m\n\u001B[0;32m--> 248\u001B[0m pred_range \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(pred[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart\u001B[39m\u001B[38;5;124m\"\u001B[39m], pred[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    249\u001B[0m true_range \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(true[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart\u001B[39m\u001B[38;5;124m\"\u001B[39m], true[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    251\u001B[0m \u001B[38;5;66;03m# Scenario IV: Offsets match, but entity type is wrong\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:47:23.822654Z",
     "start_time": "2024-12-06T19:47:11.957248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results_l12 = trainer.evaluate(Dataset(load_from_disk('data/test'), tokenizer_name='xlm-v'))\n",
    "test_results_l12"
   ],
   "id": "d24056baa716f185",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test_results_l12 \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_from_disk\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/test\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mxlm-v\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m test_results_l12\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:3666\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3663\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3665\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3666\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3667\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3669\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   3670\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   3671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3672\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3674\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3676\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3677\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/transformers/trainer.py:3956\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3952\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[1;32m   3953\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[1;32m   3954\u001B[0m         )\n\u001B[1;32m   3955\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3956\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3957\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3958\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[0;32mIn[8], line 20\u001B[0m, in \u001B[0;36mcompute_ner_metrics\u001B[0;34m(eval_pred)\u001B[0m\n\u001B[1;32m     17\u001B[0m aligned_labels \u001B[38;5;241m=\u001B[39m ner_tags_scheme[aligned_labels]\n\u001B[1;32m     19\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m nervaluate\u001B[38;5;241m.\u001B[39mEvaluator(aligned_labels, aligned_preds, tags\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPER\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLOC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mORG\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMISC\u001B[39m\u001B[38;5;124m'\u001B[39m], loader\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlist\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m results, results_per_tag, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m overall_metrics \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     24\u001B[0m per_tag_metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/nervaluate/evaluate.py:84\u001B[0m, in \u001B[0;36mEvaluator.evaluate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of predicted documents does not equal true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, (true_ents, pred_ents) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrue, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpred)):\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;66;03m# Compute results for one message\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m     tmp_results, tmp_agg_results, tmp_results_indices, tmp_agg_results_indices \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_ents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_ents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;66;03m# Cycle through each result and accumulate\u001B[39;00m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;66;03m# TODO: Combine these loops below:\u001B[39;00m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m eval_schema \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults:\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/nervaluate/evaluate.py:163\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[0;34m(true_named_entities, pred_named_entities, tags, instance_index)\u001B[0m\n\u001B[1;32m    155\u001B[0m evaluation \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ment_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexact\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    160\u001B[0m }\n\u001B[1;32m    162\u001B[0m \u001B[38;5;66;03m# results by entity type\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m evaluation_agg_entities_type \u001B[38;5;241m=\u001B[39m \u001B[43m{\u001B[49m\u001B[43me\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m    165\u001B[0m eval_ent_indices: Dict[\u001B[38;5;28mstr\u001B[39m, List[Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]]] \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorrect_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mincorrect_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspurious_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    171\u001B[0m }\n\u001B[1;32m    173\u001B[0m \u001B[38;5;66;03m# Create dicts to hold indices for correct/spurious/missing/etc examples\u001B[39;00m\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/site-packages/nervaluate/evaluate.py:163\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    155\u001B[0m evaluation \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ment_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexact\u001B[39m\u001B[38;5;124m\"\u001B[39m: deepcopy(eval_metrics),\n\u001B[1;32m    160\u001B[0m }\n\u001B[1;32m    162\u001B[0m \u001B[38;5;66;03m# results by entity type\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m evaluation_agg_entities_type \u001B[38;5;241m=\u001B[39m {e: \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluation\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m tags}\n\u001B[1;32m    165\u001B[0m eval_ent_indices: Dict[\u001B[38;5;28mstr\u001B[39m, List[Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]]] \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorrect_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mincorrect_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspurious_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    171\u001B[0m }\n\u001B[1;32m    173\u001B[0m \u001B[38;5;66;03m# Create dicts to hold indices for correct/spurious/missing/etc examples\u001B[39;00m\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/copy.py:231\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    229\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 231\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/copy.py:231\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    229\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 231\u001B[0m     y[\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m] \u001B[38;5;241m=\u001B[39m deepcopy(value, memo)\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m/mloscratch/homes/shcherba/conda/envs/char-llm/lib/python3.11/copy.py:144\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(x)\n\u001B[0;32m--> 144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     y \u001B[38;5;241m=\u001B[39m copier(x, memo)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:47:13.723893Z",
     "start_time": "2024-12-06T16:47:13.557139Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3bf13c66b8ddefe3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[torch]\r\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "90cb1610c1f20c9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
